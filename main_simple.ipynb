{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-23T09:01:07.920818Z",
     "start_time": "2024-02-23T09:01:01.070097Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.28/04\n"
     ]
    }
   ],
   "source": [
    "# %env PYTORCH_ENABLE_MPS_FALLBACK=1\n",
    "%load_ext autoreload\n",
    "%autoreload\n",
    "\n",
    "from bins import Bins\n",
    "from eventsreader import Frame\n",
    "from hist_utils import HistMaker, HistMaker1d, geom_avg1d, symmetrize, CombinedHistMaker, SignalHistMaker\n",
    "from hist_template import set_opt_text, set_th1, set_pad\n",
    "from fitting import fit_simple_model\n",
    "from plotting import plot_losses, show_results, paveTexts, show_mass_z, xtitle_root\n",
    "from ROOT import TH1, TF1, TCanvas, gStyle, TLegend\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "#!pip install openpyxl"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-23T09:01:08.029390Z",
     "start_time": "2024-02-23T09:01:07.921857Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "gStyle.SetOptStat(0)\n",
    "\n",
    "\n",
    "no_track_corr = True\n",
    "analyse_3d = False\n",
    "learn_norm = False\n",
    "same_sign_symm = False\n",
    "ag1580ag = True\n",
    "event_mixing = False\n",
    "symmetrize_explicit = False\n",
    "read_saved = False\n",
    "range_used = range(0,12)\n",
    "fraction = 100.0\n",
    "#fraction = 0.8\n",
    "frame = Frame.HX\n",
    "\n",
    "DIR_NAME = f\"results_{'ag1580ag' if ag1580ag else 'ag1230ag'}_{'3d' if analyse_3d else '1d'}_{'symm' if same_sign_symm else 'nosymm'}_{frame.name}{'_mix' if event_mixing else ''}\"\n",
    "if not os.path.isdir(DIR_NAME):\n",
    "    os.mkdir(DIR_NAME)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-23T09:01:08.142572Z",
     "start_time": "2024-02-23T09:01:08.034103Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-23T09:01:08.288156Z",
     "start_time": "2024-02-23T09:01:08.143744Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.device(\"mps\")\n",
    "torch.manual_seed(0)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use(\"bmh\")\n",
    "plt.rcParams[\"figure.figsize\"] = (8, 6)\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-23T09:01:08.411495Z",
     "start_time": "2024-02-23T09:01:08.293085Z"
    }
   },
   "outputs": [],
   "source": [
    "TH1.SetDefaultSumw2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickle file exists\n",
      "[02/23/2024, 10:01:09]: iter  0\n",
      "[02/23/2024, 10:01:09] Before processing events\n",
      "Num events 473850\n",
      "Num non-null events 473850\n",
      "[02/23/2024, 10:01:11] After processing events\n",
      "#1 result length 5\n",
      "Pickle file exists\n",
      "[02/23/2024, 10:01:11]: iter  1\n",
      "[02/23/2024, 10:01:11] Before processing events\n",
      "Num events 103993\n",
      "Num non-null events 103993\n",
      "[02/23/2024, 10:01:11] After processing events\n",
      "#1 result length 5\n",
      "Pickle file exists\n",
      "[02/23/2024, 10:01:12]: iter  2\n",
      "[02/23/2024, 10:01:12] Before processing events\n",
      "Num events 170901\n",
      "Num non-null events 170901\n",
      "[02/23/2024, 10:01:13] After processing events\n",
      "#1 result length 5\n",
      "Pickle file exists\n",
      "[02/23/2024, 10:01:16]: iter  3\n",
      "[02/23/2024, 10:01:16] Before processing events\n",
      "Num events 473850\n",
      "Num non-null events 473850\n",
      "[02/23/2024, 10:01:17] After processing events\n",
      "#1 result length 5\n",
      "Pickle file exists\n",
      "[02/23/2024, 10:01:17]: iter  4\n",
      "[02/23/2024, 10:01:17] Before processing events\n",
      "Num events 103993\n",
      "Num non-null events 103993\n",
      "[02/23/2024, 10:01:17] After processing events\n",
      "#1 result length 5\n",
      "Pickle file exists\n",
      "[02/23/2024, 10:01:19]: iter  5\n",
      "[02/23/2024, 10:01:19] Before processing events\n",
      "Num events 170901\n",
      "Num non-null events 170901\n",
      "[02/23/2024, 10:01:20] After processing events\n",
      "#1 result length 5\n",
      "Pickle file exists\n",
      "[02/23/2024, 10:01:26]: iter  6\n",
      "[02/23/2024, 10:01:26] Before processing events\n",
      "Num events 1146500\n",
      "Num non-null events 1146500\n",
      "[02/23/2024, 10:01:29] After processing events\n",
      "#1 result length 5\n",
      "Pickle file exists\n",
      "[02/23/2024, 10:01:34]: iter  7\n",
      "[02/23/2024, 10:01:34] Before processing events\n",
      "Num events 889691\n",
      "Num non-null events 889691\n",
      "[02/23/2024, 10:01:36] After processing events\n",
      "#1 result length 5\n",
      "Pickle file exists\n",
      "[02/23/2024, 10:01:50]: iter  8\n",
      "[02/23/2024, 10:01:50] Before processing events\n",
      "Num events 1607005\n",
      "Num non-null events 1607005\n",
      "[02/23/2024, 10:01:55] After processing events\n",
      "#1 result length 5\n",
      "Pickle file exists\n",
      "[02/23/2024, 10:02:11]: iter  9\n",
      "[02/23/2024, 10:02:11] Before processing events\n",
      "Num events 1146500\n",
      "Num non-null events 1146500\n",
      "[02/23/2024, 10:02:14] After processing events\n",
      "#1 result length 5\n",
      "Pickle file exists\n",
      "[02/23/2024, 10:02:33]: iter  10\n",
      "[02/23/2024, 10:02:33] Before processing events\n",
      "Num events 1146500\n",
      "Num non-null events 1146500\n",
      "[02/23/2024, 10:02:36] After processing events\n",
      "#1 result length 5\n",
      "Pickle file exists\n",
      "[02/23/2024, 10:02:59]: iter  11\n",
      "[02/23/2024, 10:02:59] Before processing events\n",
      "Num events 1607005\n",
      "Num non-null events 1607005\n",
      "[02/23/2024, 10:03:04] After processing events\n",
      "#1 result length 5\n",
      "Pickle file exists\n",
      "[02/23/2024, 10:03:04]: iter  12\n",
      "[02/23/2024, 10:03:04] Before processing events\n",
      "Num events 169435\n",
      "Num non-null events 169435\n",
      "[02/23/2024, 10:03:05] After processing events\n",
      "#1 result length 5\n",
      "Pickle file exists\n",
      "[02/23/2024, 10:03:30]: iter  13\n",
      "[02/23/2024, 10:03:30] Before processing events\n",
      "Num events 542231\n",
      "Num non-null events 542231\n",
      "[02/23/2024, 10:03:31] After processing events\n",
      "#1 result length 5\n",
      "Pickle file exists\n",
      "[02/23/2024, 10:03:33]: iter  14\n",
      "[02/23/2024, 10:03:33] Before processing events\n",
      "Num events 792444\n",
      "Num non-null events 792444\n",
      "[02/23/2024, 10:03:35] After processing events\n",
      "#1 result length 5\n",
      "Pickle file exists\n",
      "[02/23/2024, 10:04:06]: iter  15\n",
      "[02/23/2024, 10:04:06] Before processing events\n",
      "Num events 1183754\n",
      "Num non-null events 1183754\n",
      "[02/23/2024, 10:04:09] After processing events\n",
      "#1 result length 5\n",
      "Pickle file exists\n",
      "[02/23/2024, 10:04:09]: iter  16\n",
      "[02/23/2024, 10:04:09] Before processing events\n",
      "Num events 189671\n",
      "Num non-null events 189671\n",
      "[02/23/2024, 10:04:10] After processing events\n",
      "#1 result length 5\n",
      "Pickle file exists\n",
      "[02/23/2024, 10:04:12]: iter  17\n",
      "[02/23/2024, 10:04:12] Before processing events\n",
      "Num events 1200000\n",
      "Num non-null events 1200000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if ag1580ag:\n",
    "    ekin = 1580\n",
    "   # The right one\n",
    "    filename_data_np = \"063_088_ag158ag_3200A_accepted_np.dat\"\n",
    "    if no_track_corr:\n",
    "        filename_data_np = \"063_088_ag158ag_3200A_accepted_np_noTrackCorr.dat\"\n",
    "   # UrQMD\n",
    "   # filename_data_np = \"mar19_diele_no_enhancement_gcalor_np.dat\"\n",
    "   # filename_data_np = \"mar19_diele_inmedium_helip1cm_ag1580ag_np.dat\"\n",
    "   # Crosscheck\n",
    "   # filename_data_np = \"mar19_diele_inmedium_helip1cm_ag1580ag_jver22_np_newCuts_2.dat\"\n",
    "\n",
    "    filename_data_pp = \"063_088_ag158ag_3200A_accepted_pp.dat\"\n",
    "    if no_track_corr:\n",
    "        filename_data_pp = \"063_088_ag158ag_3200A_accepted_pp_noTrackCorr.dat\"\n",
    "    filename_data_nn = \"063_088_ag158ag_3200A_accepted_nn.dat\"\n",
    "    if no_track_corr:\n",
    "        filename_data_nn = \"063_088_ag158ag_3200A_accepted_nn_noTrackCorr.dat\"\n",
    "    filename_data_np_mix = \"063_088_ag158ag_3200A_accepted_np_mix_hc.dat\"\n",
    "    filename_data_pp_mix = \"apr12_diele_086_ag158ag_3200A_accepted_1_pp_mix_hc.dat\"\n",
    "    filename_data_nn_mix = \"apr12_diele_086_ag158ag_3200A_accepted_1_nn_mix_hc.dat\"\n",
    "    filename_MC_rho_4pi_heli0 = \"mar19_diele_inmedium_heli0cm_ag1580ag_jver22_2_np_kine.dat\"\n",
    "    filename_MC_rho_4pi_heli1 = \"mar19_diele_inmedium_helip1cm_ag1580ag_jver22_2_np_kine.dat\"\n",
    "   # filename_MC_rho_heli0_np = \"mar19_diele_inmedium_heli0cm_ag1580ag_np.dat\"\n",
    "   # filename_MC_rho_heli0_np = \"mar19_diele_inmedium_heli0cm_ag1580ag_jver22_np.dat\"\n",
    "   # filename_MC_rho_heli0_pp = \"mar19_diele_inmedium_heli0cm_ag1580ag_jver22_pp.dat\"\n",
    "   # filename_MC_rho_heli0_nn = \"mar19_diele_inmedium_heli0cm_ag1580ag_jver22_nn.dat\"\n",
    "   # filename_MC_rho_heli0_np = \"mar19_diele_inmedium_heli0cm_ag1580ag_jver22_np_newCuts.dat\"\n",
    "    filename_MC_rho_heli0_np = \"mar19_diele_inmedium_heli0cm_ag1580ag_jver22_np_newCuts_2.dat\"\n",
    "    if no_track_corr:\n",
    "        filename_MC_rho_heli0_np = \"inmedium_heli0cm_ag1580ag_jver22_np_noTrackCorr.dat\"\n",
    "   # Maybe right ones \n",
    "    filename_MC_rho_heli0_pp = \"mar19_diele_inmedium_heli0cm_ag1580ag_jver22_pp_newCuts.dat\"\n",
    "    filename_MC_rho_heli0_nn = \"mar19_diele_inmedium_heli0cm_ag1580ag_jver22_nn_newCuts.dat\"\n",
    "   # Check with Mixing \n",
    "   # filename_MC_rho_heli0_pp = \"mar19_diele_no_enhancement_gcalor_pp_mix.dat\"\n",
    "   # filename_MC_rho_heli0_nn = \"mar19_diele_no_enhancement_gcalor_nn_mix.dat\"\n",
    "    filename_MC_rho_heli1 = \"mar19_diele_inmedium_helip1cm_ag1580ag_jver22_np.dat\"\n",
    "    filename_MC_pi0 = \"mar19_diele_pi0_heli0cm_ag1580ag_jver22_np.dat\"\n",
    "    filename_MC_mix = \"mar19_diele_pi0_heli0cm_ag1580ag_np_mix.dat\"\n",
    "    if same_sign_symm:\n",
    "       # The right one\n",
    "        filename_data_pp = \"063_088_ag158ag_3200A_accepted_pp_symm.dat\"\n",
    "       # UrQMD\n",
    "       # filename_data_pp = \"mar19_diele_no_enhancement_gcalor_pp.dat\"\n",
    "       # The right one\n",
    "        filename_data_nn = \"063_088_ag158ag_3200A_accepted_nn_symm.dat\"\n",
    "       # UrQMD\n",
    "       # filename_data_nn = \"mar19_diele_no_enhancement_gcalor_nn.dat\"\n",
    "       # filename_data_pp_mix = \"apr12_diele_086_ag158ag_3200A_accepted_1_pp_mix_hc_symm.dat\"\n",
    "       # filename_data_nn_mix = \"apr12_diele_086_ag158ag_3200A_accepted_1_nn_mix_hc_symm.dat\"\n",
    "       # filename_MC_rho_heli0_pp = \"mar19_diele_inmedium_heli0cm_ag1580ag_jver22_pp_swapRandomly.dat\"\n",
    "       # filename_MC_rho_heli0_nn = \"mar19_diele_inmedium_heli0cm_ag1580ag_jver22_nn_swapRandomly.dat\"\n",
    "else:\n",
    "    ekin = 1230\n",
    "   # filename_data_np = \"apr12_diele_088_090_ag123ag_2500A_accepted_np_2.dat\"\n",
    "    filename_data_np = \"mar19_diele_inmedium_helip1cm_ag1230ag_\"\n",
    "    filename_data_pp = \"088_090_ag123ag_2500A_accepted_pp.dat\"\n",
    "    filename_data_nn = \"088_090_ag123ag_2500A_accepted_nn.dat\"\n",
    "    filename_data_np_mix = \"apr12_diele_089_ag123ag_2500A_accepted_93_np_mix_hc.dat\"\n",
    "    filename_data_pp_mix = \"088_090_ag123ag_2500A_accepted_pp_mix_hc.dat\"\n",
    "    filename_data_nn_mix = \"088_090_ag123ag_2500A_accepted_nn_mix_hc.dat\"\n",
    "    filename_MC_rho_heli0_np = \"mar19_diele_inmedium_heli0cm_ag1230ag_jver22_np.dat\"\n",
    "    filename_MC_rho_heli0_pp = \"mar19_diele_inmedium_heli0cm_ag1230ag_jver22_pp.dat\"\n",
    "    filename_MC_rho_heli0_nn = \"mar19_diele_inmedium_heli0cm_ag1230ag_jver22_nn.dat\"\n",
    "    filename_MC_rho_heli1 = \"mar19_diele_inmedium_helip1cm_ag1580ag_jver22_np.dat\"\n",
    "    filename_MC_pi0 = \"mar19_diele_pi0_heli0cm_ag1580ag_np.dat\"\n",
    "    filename_MC_mix = \"mar19_diele_pi0_heli0cm_np_mix.dat\"\n",
    "\n",
    "HistMakerClass = HistMaker if analyse_3d else HistMaker1d\n",
    "\n",
    "bins = Bins.readFrom(\"ranges.yml\")\n",
    "#histMakerData_np = HistMakerClass(\"apr12_diele_088_090_ag123ag_2500A_accepted_np_mix_hc_sample_2.dat\", \"_data\", bins, frame)\n",
    "if event_mixing:\n",
    "    histMakerData_np = HistMakerClass(filename_data_np_mix, \"_data_np\", bins, frame, ekin)\n",
    "else:\n",
    "    histMakerData_np = HistMakerClass(filename_data_np, \"_data_np\", bins, frame, ekin)\n",
    "histsData_np = histMakerData_np.make_hists  ()\n",
    "histMakerData_pp = HistMakerClass(filename_data_pp, \"_data_pp\", bins, frame, ekin)\n",
    "histsData_pp = histMakerData_pp.make_hists()\n",
    "histMakerData_nn = HistMakerClass(filename_data_nn, \"_data_nn\", bins, frame, ekin)\n",
    "histsData_nn = histMakerData_nn.make_hists()\n",
    "\n",
    "histMakerData_sig = SignalHistMaker(\n",
    "    HistMakerClass(filename_data_np, \"_data_sig\", bins, frame, ekin),\n",
    "    HistMakerClass(filename_data_pp, \"_data_ppb\", bins, frame, ekin), \n",
    "    HistMakerClass(filename_data_nn, \"_data_nnb\", bins, frame, ekin),\n",
    "    HistMakerClass(filename_data_np_mix, \"_data_npk\", bins, frame, ekin),\n",
    "    HistMakerClass(filename_data_pp_mix, \"_data_ppk\", bins, frame, ekin), \n",
    "    HistMakerClass(filename_data_nn_mix, \"_data_nnk\", bins, frame, ekin))\n",
    "\n",
    "histsData_sig, histsData_bgr, histsData_k = histMakerData_sig.make_hists()\n",
    "\n",
    "histMakerData_np_mix = HistMakerClass(filename_data_np_mix, \"_data_np_mix\", bins, frame, ekin)\n",
    "histsData_np_mix = histMakerData_np_mix.make_hists()\n",
    "histMakerData_pp_mix = HistMakerClass(filename_data_np_mix, \"_data_pp_mix\", bins, frame, ekin)\n",
    "histsData_pp_mix = histMakerData_pp_mix.make_hists()\n",
    "histMakerData_nn_mix = HistMakerClass(filename_data_nn_mix, \"_data_nn_mix\", bins, frame, ekin)\n",
    "histsData_nn_mix = histMakerData_nn_mix.make_hists()\n",
    "\n",
    "histMakerMC_rho_heli0_np = HistMakerClass(filename_MC_rho_heli0_np, \"_MC_rho_heli0\", bins, frame, ekin)\n",
    "histMakerMC_rho_heli0_pp = HistMakerClass(filename_MC_rho_heli0_pp, \"_MC_rho_heli0_pp\", bins, frame, ekin)\n",
    "histMakerMC_rho_heli0_nn = HistMakerClass(filename_MC_rho_heli0_nn, \"_MC_rho_heli0_nn\", bins, frame, ekin)\n",
    "histMakerMC_rho_heli1 = HistMakerClass(filename_MC_rho_heli1, \"_MC_rho_heli1\", bins, frame, ekin)\n",
    "histMakerMC_pi0 = HistMakerClass(filename_MC_pi0, \"_MC_pi0\", bins, frame, ekin)\n",
    "histMakerMC_mix = HistMakerClass(filename_MC_mix, \"_MC_mix\", bins, frame, ekin)\n",
    "#histMakerMC_mix = HistMakerClass(\"test_inmedium_heli0cm_np_mix.dat\", \"_MC_rho_mix\", bins, frame)\n",
    "#histMakerMC_mix = HistMakerClass(\"mar19_diele_pi0_heli0cm_np_mix.dat\", \"_MC_rho_mix\", bins, frame)\n",
    "def get_hist_maker_mc(sign, hist_index):\n",
    "    if event_mixing:\n",
    "        return histMakerMC_mix\n",
    "    else:\n",
    "        if hist_index < 3:\n",
    "            return CombinedHistMaker(histMakerMC_pi0, histMakerMC_rho_heli0_np, fraction)\n",
    "        else:\n",
    "            if sign in [\"np\", \"sig\", \"bgr\", \"k\"]:\n",
    "                return histMakerMC_rho_heli0_np\n",
    "            elif sign == \"pp\":\n",
    "                return histMakerMC_rho_heli0_pp\n",
    "            else:\n",
    "                return histMakerMC_rho_heli0_nn\n",
    "        # return histMakerMC_rho_heli0_np"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-02-23T09:01:08.412982Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#print(histsData_sig)\n",
    "print(histsData_bgr)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "torch.backends.mps.is_available()\n",
    "#mps_device = torch.device(\"mps\")\n",
    "mps_device = torch.device(\"cpu\")\n",
    "bounds = torch.tensor([[-2, ],\n",
    "                       [ 2, ]], dtype=torch.float)\n",
    "bounds = bounds.to(mps_device)\n",
    "\n",
    "\n",
    "xs = torch.linspace(bounds[0][0], bounds[1][0], 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "parameters_all_np, losses_all_np = fit_simple_model(histsData_np, get_hist_maker_mc, range_used, learn_norm, analyse_3d)\n",
    "parameters_all_pp, losses_all_pp = fit_simple_model(histsData_pp, get_hist_maker_mc, range_used, learn_norm, analyse_3d)\n",
    "parameters_all_nn, losses_all_nn = fit_simple_model(histsData_nn, get_hist_maker_mc, range_used, learn_norm, analyse_3d)\n",
    "parameters_all_sig, losses_all_sig = fit_simple_model(histsData_sig, get_hist_maker_mc, range_used, learn_norm, analyse_3d)\n",
    "parameters_all_bgr, losses_all_bgr = fit_simple_model(histsData_bgr, get_hist_maker_mc, range_used, learn_norm, analyse_3d)\n",
    "parameters_all_k, losses_all_k = fit_simple_model(histsData_k, get_hist_maker_mc, range_used, learn_norm, analyse_3d)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Plotting e+e- pairs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig_np, ax_np = plot_losses(losses_all_np, range_used)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Calculating covariance matrix for parameters\n",
    "\n",
    "In general, if the value of the fitted model with $m$ parameters at point $x_i$ can be expressed as ({cite}`@cowan1998statistical`):\n",
    "$$f(x_i,\\mathbf{\\lambda})=\\sum_{j=1}^{m}a_j(x_i)\\lambda_j\\equiv\\sum_{j=1}^{m}A_{ij}\\lambda_j,$$\n",
    "then the expression for $\\chi^2$ is:\n",
    "$$\\chi^2=(\\mathbf{y}-A\\mathbf{\\lambda})^T V^{-1}(\\mathbf{y}-A\\mathbf{\\lambda}),$$\n",
    "where $V$ is the covariance matrix of different data points. We have only statistical errors at each data point (histogram bin in our case), so we assume, witn $n$ data points (bins),\n",
    "$$V^{-1}=\\mathrm{diag}\\left(\\frac{1}{\\sigma^2_{1}},\\frac{1}{\\sigma^2_{2}},\\frac{1}{\\sigma^2_{3}},...,\\frac{1}{\\sigma^2_{n}}\\right).$$\n",
    "The covariance matrix for for parameters, $U_{ij}=\\mathrm{cov}[\\hat{\\lambda}_i,\\hat{\\lambda}_j]$ is calculated as\n",
    "$$U=(A^TV^{-1}A)^{-1}.$$\n",
    "In our case, the $i$-th row of matrix $A$, corresponding to the $i$-th data point (bin) has the following form:\n",
    "$$\\left(\\frac{c_i}{I}\\;\\;\\;\\frac{c_i}{I}\\cos^2(\\theta_i)\\;\\;\\;\\frac{c_i}{I}\\sin(2\\theta_i)cos(\\phi_i)\\;\\;\\;\\frac{c_i}{I}\\sin^2(\\theta_i)\\cos(2\\phi_i)\\right),$$\n",
    "where $\\theta_i$, $\\phi_i$ are values corresponding the bin center. Note, that one of the axes is $\\cos(\\theta)$, so $\\arccos$ has to be calculated. $c_i$ is the bin content of the **unweighted** model histogram. $I$ is the integral of the model histogram **after applying the weights**. Thanks to that, the weighted histogram is always normalized to unity and can be compared to the experimental data histogram ($\\mathbf{y}$) which is also normalized to unity all the time.\n",
    "\n",
    "For the errors of the fit parameters, we just use square roots of the diagonal elements of the matrix $U$. However, with the matrix $A$ given above, we calculate the covariance matrix for the fit:\n",
    "$$f(\\theta,\\phi)=A+B\\cos^2(\\theta_i)+C\\sin(2\\theta_i)cos(\\phi_i)+D\\sin^2(\\theta_i)\\cos(2\\phi_i).$$\n",
    "In order to get correct errors of the parameters of the fit:\n",
    "$$f(\\theta,\\phi)\\propto1+\\lambda_\\theta\\cos^2(\\theta_i)+\\lambda_{\\theta\\phi}\\sin(2\\theta_i)cos(\\phi_i)+\\lambda_\\phi\\sin^2(\\theta_i)\\cos(2\\phi_i),$$\n",
    "we use error propagation to calculate the errors of ratios of ${B, C, D}$ parameters to $A$.\n",
    "\n",
    "{bibliography}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_np = show_results(\"np\", DIR_NAME, range_used, parameters_all_np, get_hist_maker_mc, bins, histsData_np, analyse_3d)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Plotting e+e+ pairs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig_pp, ax_pp = plot_losses(losses_all_pp, range_used)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_pp = show_results(\"pp\", DIR_NAME, range_used, parameters_all_pp, get_hist_maker_mc, bins, histsData_pp, analyse_3d)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Plotting e-e- pairs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig_nn, ax_nn = plot_losses(losses_all_nn, range_used)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_nn = show_results(\"nn\", DIR_NAME, range_used, parameters_all_nn, get_hist_maker_mc, bins, histsData_nn, analyse_3d)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Plotting signal"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig_sig, ax_sig = plot_losses(losses_all_sig, range_used)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_sig = show_results(\"sig\", DIR_NAME, range_used, parameters_all_sig, get_hist_maker_mc, bins, histsData_sig, analyse_3d)\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Plotting combinatorial background"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig_bgr, ax_bgr = plot_losses(losses_all_bgr, range_used)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_bgr = show_results(\"bgr\", DIR_NAME, range_used, parameters_all_bgr, get_hist_maker_mc, bins, histsData_bgr, analyse_3d)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Plotting $k$-factor"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig_k, ax_k = plot_losses(losses_all_k, range_used)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_k = show_results(\"k\", DIR_NAME, range_used, parameters_all_k, get_hist_maker_mc, bins, histsData_k, analyse_3d)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if not analyse_3d:\n",
    "    histsDataCorrs = []\n",
    "    histsDatas = []\n",
    "    histsModels = []\n",
    "    legends = []\n",
    "    hmodel_null = histMakerMC_rho_heli0_np.make_hists((0.0))\n",
    "    hmodel_null_pp = histMakerMC_rho_heli0_pp.make_hists((0.0))\n",
    "    hmodel_null_nn = histMakerMC_rho_heli0_nn.make_hists((0.0))\n",
    "    hmodel_null_mix = histMakerMC_mix.make_hists((0.0))\n",
    "    hmodel_null_pi0 = histMakerMC_pi0.make_hists((0.0))\n",
    "    hmodel_null_heli1 = histMakerMC_rho_heli1.make_hists((0.0))\n",
    "\n",
    "    pol2s = []\n",
    "    histsAvg = []\n",
    "    kfactors = []\n",
    "\n",
    "    cc4 = TCanvas(\"cc4\",\"cc4\",900,1200)\n",
    "    cc4.Divide(3,4)\n",
    "    cc4.Draw()\n",
    "\n",
    "    cck = TCanvas(\"cck\",\"cck\",900,1200)\n",
    "    cck.Divide(3,4)\n",
    "\n",
    "    csig = TCanvas(\"csig\",\"csig\",900,1200)\n",
    "    csig.Divide(3,4)\n",
    "\n",
    "    cacc = TCanvas(\"cacc\",\"cacc\",900,1200)\n",
    "    cacc.Divide(3,4)\n",
    "\n",
    "    for i, hist_np in enumerate(histsData_np[0]):\n",
    "    \n",
    "        if not isinstance(hist_np, list):\n",
    "\n",
    "            hist_pp = histsData_pp[0][i]\n",
    "            hist_nn = histsData_nn[0][i]\n",
    "        \n",
    "            if symmetrize_explicit:\n",
    "                symmetrize(hist_np)\n",
    "                symmetrize(hist_pp)\n",
    "                symmetrize(hist_nn)\n",
    "        \n",
    "            histAvg = geom_avg1d(hist_pp, hist_nn, 0.2)\n",
    "            histsAvg.append(histAvg)\n",
    "\n",
    "        \n",
    "            histCorr_np = hist_np.Clone(hist_np.GetName() + \"_corr\")\n",
    "            histCorr_pp = hist_pp.Clone(hist_pp.GetName() + \"_corr\")\n",
    "            histCorr_nn = hist_nn.Clone(hist_nn.GetName() + \"_corr\")\n",
    "            histsDataCorrs.append(histCorr_np)\n",
    "            histsDataCorrs.append(histCorr_pp)\n",
    "            histsDataCorrs.append(histCorr_nn)\n",
    "            histCorr_np.GetXaxis().SetTitle(xtitle_root)\n",
    "        \n",
    "            pad = cc4.cd(i+1)\n",
    "            set_pad(pad)       \n",
    "       \n",
    "            hist_kfactor = histsData_np_mix[0][i]\n",
    "            hist_pp_mix = histsData_pp_mix[0][i]\n",
    "            hist_nn_mix = histsData_nn_mix[0][i]\n",
    "\n",
    "            if symmetrize_explicit:\n",
    "                symmetrize(hist_kfactor)\n",
    "                symmetrize(hist_pp_mix)\n",
    "                symmetrize(hist_nn_mix)\n",
    "\n",
    "            histAvg_mix = geom_avg1d(hist_pp_mix, hist_nn_mix, 0.2)\n",
    "            hist_kfactor.Divide(histAvg_mix)\n",
    "            hist_kfactor.Scale(2)\n",
    "            kfactors.append(hist_kfactor)\n",
    "\n",
    "            pad = cck.cd(i+1)\n",
    "            set_pad(pad)\n",
    "\n",
    "            hist_kfactor.GetXaxis().SetTitle(xtitle_root)\n",
    "        \n",
    "            set_th1(hist_kfactor, histCorr_np.GetXaxis().GetTitle(), \"#it{k}-factor\", \n",
    "                   505, 20, 0.8, 1)\n",
    "            hist_pp_mix.SetLineColor(2)\n",
    "            hist_nn_mix.SetLineColor(4)\n",
    "            hist_pp_mix.SetMarkerColor(2)\n",
    "            hist_nn_mix.SetMarkerColor(4)\n",
    "            hist_kfactor.Draw()\n",
    "            hist_pp_mix.Draw(\"SAME\")\n",
    "            hist_nn_mix.Draw(\"SAME\")\n",
    "            hist_kfactor.SetMinimum(0)\n",
    "             \n",
    "            pad = cc4.cd(i+1)\n",
    "            set_pad(pad)       \n",
    "            \n",
    "            histAvg_withK = histAvg.Clone(histAvg.GetName() + \"_withK\")\n",
    "            histsAvg.append(histAvg_withK)\n",
    "            histAvg_withK.Multiply(hist_kfactor)\n",
    "            \n",
    "            histAvg_withK.SetFillStyle(3004)\n",
    "            histAvg_withK.SetFillColor(45)\n",
    "            histAvg_withK.SetLineColor(45)\n",
    "            histAvg.SetLineColor(6)\n",
    "            hist_pp.SetLineColor(4)\n",
    "            hist_nn.SetLineColor(2)\n",
    "                    \n",
    "            set_th1(hist_np, histCorr_np.GetXaxis().GetTitle(), f\"dN/d{histCorr_np.GetXaxis().GetTitle()} (a.u.)\", \n",
    "                   505, 20, 0.8, 1)\n",
    "            hist_np.SetMinimum(0)\n",
    "            hist_np.Draw()\n",
    "            histAvg_withK.Draw(\"SAMEHIST\")\n",
    "            histAvg.Draw(\"SAMEHIST\")\n",
    "            hist_pp.Draw(\"SAMEHIST\")\n",
    "            hist_nn.Draw(\"SAMEHIST\")\n",
    "            \n",
    "            pad = csig.cd(i+1)\n",
    "            set_pad(pad)     \n",
    "    \n",
    "            hist_model_np = hmodel_null_mix[0][i]\n",
    "            # TODO: make it consistent if we go the way of using mixing\n",
    "            hist_model_pp = hmodel_null_mix[0][i]\n",
    "            hist_model_nn = hmodel_null_mix[0][i]\n",
    "            if not event_mixing:\n",
    "                if i < 3:\n",
    "                    hist_model_np = hmodel_null_pi0[0][i]\n",
    "                    # TODO: make is consisnt if combinatorial background really matters for the pi0 region\n",
    "                    hist_model_pp = hmodel_null_pi0[0][i]\n",
    "                    hist_model_nn = hmodel_null_pi0[0][i]\n",
    "                else:\n",
    "                    hist_model_np = hmodel_null[0][i]\n",
    "                    hist_model_pp = hmodel_null_pp[0][i]\n",
    "                    hist_model_nn = hmodel_null_nn[0][i]\n",
    "            if symmetrize_explicit:\n",
    "                symmetrize(hist_model_np)\n",
    "    \n",
    "           # histCorr_np.Add(histAvg_withK,-1)\n",
    "            histCorr_np.Divide(hist_model_np)\n",
    "            histCorr_pp.Divide(hist_model_pp)\n",
    "            histCorr_nn.Divide(hist_model_nn)\n",
    "            \n",
    "            histAvgCorr = geom_avg1d(histCorr_pp, histCorr_nn, 0.2)\n",
    "            histsAvg.append(histAvgCorr)\n",
    "            histAvgCorr_withK = histAvgCorr.Clone(histAvgCorr.GetName() + \"_withK\")\n",
    "            histsAvg.append(histAvgCorr_withK)\n",
    "            histAvgCorr_withK.Multiply(hist_kfactor)\n",
    "        \n",
    "            s2b = (hist_np.Integral() - histAvg_withK.Integral()) / histAvg_withK.Integral()\n",
    "            s2b_corr = (histCorr_np.Integral() - histAvgCorr_withK.Integral()) / histAvgCorr_withK.Integral()\n",
    "            histCorr_pp.Scale(s2b/s2b_corr)\n",
    "            histCorr_nn.Scale(s2b/s2b_corr)\n",
    "            histAvgCorr.Scale(s2b/s2b_corr)\n",
    "            histAvgCorr_withK.Scale(s2b/s2b_corr)\n",
    "        \n",
    "            histAvgCorr_withK.SetFillStyle(3004)\n",
    "            histAvgCorr_withK.SetFillColor(45)\n",
    "            histAvgCorr_withK.SetLineColor(45)\n",
    "            histAvgCorr.SetLineColor(6)\n",
    "    \n",
    "            #if symmetrize_explicit:    \n",
    "                #symmetrize(histCorr_np)\n",
    "    \n",
    "            fit = TF1(f\"fit_{i}\", \"[0]*(1+[1]*x*x)\",-1.0,1.0)\n",
    "            fit.SetParameters(1, 1)\n",
    "            \n",
    "            histCorr_np.Fit(fit,\"Q\")\n",
    "            pol2s.append(fit)\n",
    "        \n",
    "            set_th1(histCorr_np, histCorr_np.GetXaxis().GetTitle(), f\"dN/d{histCorr_np.GetXaxis().GetTitle()} (a.u.)\", \n",
    "                   505, 20, 0.8, 1)\n",
    "        \n",
    "            histCorr_pp.SetLineColor(4)\n",
    "            histCorr_nn.SetLineColor(2)\n",
    "            histCorr_np.Draw()\n",
    "            histCorr_pp.Draw(\"SAMEHIST\")\n",
    "            histCorr_nn.Draw(\"SAMEHIST\")\n",
    "            histAvgCorr.Draw(\"SAMEHIST\")\n",
    "            histAvgCorr_withK.Draw(\"SAMEHIST\")\n",
    "            if i < 3:\n",
    "                # histCorr_np.GetYaxis().SetRangeUser(0,2.5)\n",
    "                histCorr_np.GetYaxis().SetRangeUser(0,20)\n",
    "            else:\n",
    "                # histCorr_np.GetYaxis().SetRangeUser(0,1.25)    \n",
    "                histCorr_np.GetYaxis().SetRangeUser(0,2)    \n",
    "            histCorr_np.SetMinimum(0)\n",
    "            \n",
    "            caption = f\"#lambda_{{#theta}} = {fit.GetParameter(1):.2f} #pm {fit.GetParError(1):.2f}\"\n",
    "            paveText = set_opt_text(caption, 0.25,0.76,0.675,0.88, 2, 0.04)\n",
    "            paveTexts.append(paveText)\n",
    "    \n",
    "            if i == 4:\n",
    "                l = TLegend(0.3,0.45,0.8,0.8)\n",
    "                l.SetBorderSize(0)\n",
    "                l.AddEntry(histCorr_np,\"e+e- pairs\",\"pl\")\n",
    "                l.AddEntry(histCorr_pp,\"e+e+ pairs\",\"l\")\n",
    "                l.AddEntry(histCorr_nn,\"e-e- pairs\",\"l\")\n",
    "                l.AddEntry(histAvgCorr,\"geom. mena\",\"pl\")\n",
    "                l.AddEntry(histAvgCorr_withK,\"geom. mena with k-factor\",\"pl\")\n",
    "                l.Draw()\n",
    "                legends.append(l)\n",
    "            \n",
    "    \n",
    "            pad = cacc.cd(i+1)\n",
    "            set_pad(pad)\n",
    "            \n",
    "            hacc_heli0 = hmodel_null[0][i]\n",
    "            hacc_heli1 = hmodel_null_heli1[0][i]\n",
    "    \n",
    "        else:\n",
    "            print(hist_np)\n",
    "    \n",
    "    cc4.SaveAs(f\"{DIR_NAME}/fit_classic.gif\")\n",
    "    cc4.SaveAs(f\"{DIR_NAME}/fit_classic.pdf\")\n",
    "        \n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if not analyse_3d:\n",
    "    cck.Draw()\n",
    "    cck.SaveAs(f\"{DIR_NAME}/kfactor.gif\")\n",
    "    \n",
    "    csig.Draw()\n",
    "    csig.SaveAs(f\"{DIR_NAME}/signal.gif\")\n",
    "    csig.SaveAs(f\"{DIR_NAME}/signal.eps\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "can_mass_z_np = show_mass_z(histsData_np, histMakerMC_pi0, histMakerMC_rho_heli0_np, histMakerMC_mix, event_mixing, fraction, DIR_NAME, \"np\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "can_mass_z_pp = show_mass_z(histsData_pp, histMakerMC_pi0, histMakerMC_rho_heli0_pp, histMakerMC_mix, event_mixing, fraction, DIR_NAME, \"pp\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "can_mass_z_np = show_mass_z(histsData_nn, histMakerMC_pi0, histMakerMC_rho_heli0_nn, histMakerMC_mix, event_mixing, fraction, DIR_NAME, \"nn\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "can_mass_z_sig = show_mass_z(histsData_sig, histMakerMC_pi0, histMakerMC_rho_heli0_np, histMakerMC_mix, event_mixing, fraction, DIR_NAME, \"sig\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if not analyse_3d:\n",
    "    cacc.Draw()\n",
    "    cacc.SaveAs(f\"{DIR_NAME}/cacc.gif\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "a_np = df_np['yield']/(math.pi * (df_np['lambda_theta'] + 3)) * (3./4)\n",
    "a_pp = df_pp['yield']/(math.pi * (df_pp['lambda_theta'] + 3)) * (3./4)\n",
    "a_nn = df_nn['yield']/(math.pi * (df_nn['lambda_theta'] + 3)) * (3./4)\n",
    "\n",
    "yield_sig = df_np['yield'] - df_pp['yield'] - df_nn['yield'] \n",
    "\n",
    "term_np = (4./15) * a_np * math.pi * (5 + 3*df_np['lambda_theta'])\n",
    "term_pp = (4./15) * a_pp * math.pi * (5 + 3*df_pp['lambda_theta'])\n",
    "term_nn = (4./15) * a_nn * math.pi * (5 + 3*df_nn['lambda_theta'])\n",
    "\n",
    "term_x = term_np - 1.0*(term_pp + term_nn)\n",
    "lambda_theta_sig = (3 * term_x - 5 * yield_sig) / (3 * yield_sig - term_x)\n",
    "\n",
    "a_sig = yield_sig/(math.pi * (lambda_theta_sig + 3)) * (3./4)\n",
    "\n",
    "lambda_phi_sig = (a_np * df_np['lambda_phi'] - a_pp * df_pp['lambda_phi'] - a_nn * df_nn['lambda_phi']) / a_sig\n",
    "lambda_theta_phi_sig = (a_np * df_np['lambda_theta_phi'] - a_pp * df_pp['lambda_theta_phi'] - a_nn * df_nn['lambda_theta_phi']) / a_sig\n",
    "\n",
    "df_result = pd.DataFrame(columns=['a_np', 'a_pp', 'a_nn', 'yield_sig', 'term_np', 'term_pp', 'term_nn', 'term_x', 'a_sig', 'lambda_theta_sig', 'lambda_phi_sig', 'lambda_theta_phi_sig'])\n",
    "df_result['a_np'] = a_np\n",
    "df_result['a_pp'] = a_pp\n",
    "df_result['a_nn'] = a_nn\n",
    "df_result['term_np'] = term_np\n",
    "df_result['term_pp'] = term_pp\n",
    "df_result['term_nn'] = term_nn\n",
    "df_result['term_x'] = term_x\n",
    "df_result['yield_sig'] = yield_sig\n",
    "df_result['a_sig'] = a_sig\n",
    "df_result['lambda_theta_sig'] = lambda_theta_sig\n",
    "df_result['lambda_phi_sig'] = lambda_phi_sig\n",
    "df_result['lambda_theta_phi_sig'] = lambda_theta_phi_sig\n",
    "\n",
    "df_result"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
