{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-12T15:01:31.478948Z",
     "start_time": "2024-01-12T15:01:27.801998Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.28/04\n"
     ]
    }
   ],
   "source": [
    "# %env PYTORCH_ENABLE_MPS_FALLBACK=1\n",
    "%load_ext autoreload\n",
    "%autoreload\n",
    "\n",
    "from bins import Bins\n",
    "from eventsreader import Frame\n",
    "from hist_utils import HistMaker, HistMaker1d, geom_avg1d, symmetrize\n",
    "from hist_template import set_opt_text, set_th1, set_pad\n",
    "import helicity_model_1d\n",
    "import helicity_model_3d\n",
    "from plotting import plot_losses, show_results, paveTexts, show_mass_z\n",
    "from ROOT import TH1, TF1, TCanvas, gStyle, TLegend\n",
    "import calendar, os\n",
    "from time import gmtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "gStyle.SetOptStat(0)\n",
    "\n",
    "analyse_3d = True\n",
    "learn_norm = False\n",
    "same_sign_symm = True\n",
    "ag1580ag = True\n",
    "event_mixing = False\n",
    "symmetrize_explicit = False\n",
    "read_saved = False\n",
    "range_used = range(0,12)\n",
    "fraction = 0.8\n",
    "\n",
    "if read_saved:\n",
    "    if event_mixing:\n",
    "        if ag1580ag:\n",
    "            DIR_NAME = \"results_mixing_nu15_noise1em1_1d_ag1580ag\"\n",
    "        else:\n",
    "            DIR_NAME = \"results_mixing_nu15_noise1em1_1d\"\n",
    "    else:\n",
    "        if ag1580ag:\n",
    "           # DIR_NAME = \"results_sameevt_nu15_noise1em1_1d_ag1580ag_noconstr\"\n",
    "           # DIR_NAME = \"results_helip1cm_nu15_noise1em1_1d_ag1580ag_noconstr\"\n",
    "           # DIR_NAME = \"results_helip1cm_nu15_noise1em1_1d_ag1580ag_noconstr_vertexsim_epem\"\n",
    "            DIR_NAME = \"results_1702372287\"\n",
    "        else:\n",
    "            DIR_NAME = \"results_sameevt_nu15_noise1em1_1d\"\n",
    "else:\n",
    "    current_GMT =   gmtime()\n",
    "    time_stamp = calendar.timegm(current_GMT)\n",
    "    DIR_NAME = f'results_{time_stamp}'\n",
    "    os.mkdir(DIR_NAME)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-12T15:01:31.594144Z",
     "start_time": "2024-01-12T15:01:31.482960Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-12T15:01:31.746826Z",
     "start_time": "2024-01-12T15:01:31.595338Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.device(\"mps\")\n",
    "torch.manual_seed(0)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use(\"bmh\")\n",
    "plt.rcParams[\"figure.figsize\"] = (8, 6)\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-12T15:01:31.863649Z",
     "start_time": "2024-01-12T15:01:31.747126Z"
    }
   },
   "outputs": [],
   "source": [
    "TH1.SetDefaultSumw2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickle file exists\n",
      "[01/12/2024, 16:01:33]: iter  0\n",
      "[01/12/2024, 16:01:33] Before processing events\n",
      "Num events 411996\n",
      "Num non-null events 411996\n"
     ]
    }
   ],
   "source": [
    "from hist_utils import CombinedHistMaker\n",
    "\n",
    "if ag1580ag:\n",
    "    ekin = 1580\n",
    "    filename_data_np = \"063_088_ag158ag_3200A_accepted_np.dat\"\n",
    "   # filename_data_np = \"mar19_diele_inmedium_helip1cm_ag1580ag_np.dat\"\n",
    "   # filename_data_np = \"mar19_diele_inmedium_helip1cm_ag1580ag_jver22_np.dat\"\n",
    "    filename_data_pp = \"063_088_ag158ag_3200A_accepted_pp.dat\"\n",
    "    filename_data_nn = \"063_088_ag158ag_3200A_accepted_nn.dat\"\n",
    "    filename_data_np_mix = \"063_088_ag158ag_3200A_accepted_np_mix_hc.dat\"\n",
    "    filename_data_pp_mix = \"apr12_diele_086_ag158ag_3200A_accepted_1_pp_mix_hc.dat\"\n",
    "    filename_data_nn_mix = \"apr12_diele_086_ag158ag_3200A_accepted_1_nn_mix_hc.dat\"\n",
    "    filename_MC_rho_4pi_heli0 = \"mar19_diele_inmedium_heli0cm_ag1580ag_jver22_2_np_kine.dat\"\n",
    "    filename_MC_rho_4pi_heli1 = \"mar19_diele_inmedium_helip1cm_ag1580ag_jver22_2_np_kine.dat\"\n",
    "   # filename_MC_rho_heli0_np = \"mar19_diele_inmedium_heli0cm_ag1580ag_np.dat\"\n",
    "   # filename_MC_rho_heli0_np = \"mar19_diele_inmedium_heli0cm_ag1580ag_jver22_np.dat\"\n",
    "   # filename_MC_rho_heli0_pp = \"mar19_diele_inmedium_heli0cm_ag1580ag_jver22_pp.dat\"\n",
    "   # filename_MC_rho_heli0_nn = \"mar19_diele_inmedium_heli0cm_ag1580ag_jver22_nn.dat\"\n",
    "    filename_MC_rho_heli0_np = \"mar19_diele_inmedium_heli0cm_ag1580ag_jver22_np_newCuts.dat\"\n",
    "    filename_MC_rho_heli0_pp = \"mar19_diele_inmedium_heli0cm_ag1580ag_jver22_pp_newCuts.dat\"\n",
    "    filename_MC_rho_heli0_nn = \"mar19_diele_inmedium_heli0cm_ag1580ag_jver22_nn_newCuts.dat\"\n",
    "    filename_MC_rho_heli1 = \"mar19_diele_inmedium_helip1cm_ag1580ag_jver22_np.dat\"\n",
    "    filename_MC_pi0 = \"mar19_diele_pi0_heli0cm_ag1580ag_jver22_np.dat\"\n",
    "    filename_MC_mix = \"mar19_diele_pi0_heli0cm_ag1580ag_np_mix.dat\"\n",
    "    if same_sign_symm:\n",
    "        filename_data_pp = \"063_088_ag158ag_3200A_accepted_pp_symm.dat\"\n",
    "        filename_data_nn = \"063_088_ag158ag_3200A_accepted_nn_symm.dat\"\n",
    "       # filename_data_pp_mix = \"apr12_diele_086_ag158ag_3200A_accepted_1_pp_mix_hc_symm.dat\"\n",
    "       # filename_data_nn_mix = \"apr12_diele_086_ag158ag_3200A_accepted_1_nn_mix_hc_symm.dat\"\n",
    "       # filename_MC_rho_heli0_pp = \"mar19_diele_inmedium_heli0cm_ag1580ag_jver22_pp_swapRandomly.dat\"\n",
    "       # filename_MC_rho_heli0_nn = \"mar19_diele_inmedium_heli0cm_ag1580ag_jver22_nn_swapRandomly.dat\"\n",
    "else:\n",
    "    ekin = 1230\n",
    "    filename_data_np = \"apr12_diele_088_090_ag123ag_2500A_accepted_np_2.dat\"\n",
    "    filename_data_pp = \"088_090_ag123ag_2500A_accepted_pp.dat\"\n",
    "    filename_data_nn = \"088_090_ag123ag_2500A_accepted_nn.dat\"\n",
    "    filename_data_np_mix = \"apr12_diele_089_ag123ag_2500A_accepted_93_np_mix_hc.dat\"\n",
    "    filename_data_pp_mix = \"088_090_ag123ag_2500A_accepted_pp_mix_hc.dat\"\n",
    "    filename_data_nn_mix = \"088_090_ag123ag_2500A_accepted_nn_mix_hc.dat\"\n",
    "    filename_MC_rho_heli0_np = \"mar19_diele_inmedium_heli0cm_ag1230ag_jver22_np.dat\"\n",
    "    filename_MC_rho_heli0_pp = \"mar19_diele_inmedium_heli0cm_ag1230ag_jver22_pp.dat\"\n",
    "    filename_MC_rho_heli0_nn = \"mar19_diele_inmedium_heli0cm_ag1230ag_jver22_nn.dat\"\n",
    "    filename_MC_rho_heli1 = \"mar19_diele_inmedium_helip1cm_ag1580ag_jver22_np.dat\"\n",
    "    filename_MC_pi0 = \"mar19_diele_pi0_heli0cm_ag1580ag_np.dat\"\n",
    "    filename_MC_mix = \"mar19_diele_pi0_heli0cm_np_mix.dat\"\n",
    "\n",
    "\n",
    "frame = Frame.HX\n",
    "\n",
    "HistMakerClass = HistMaker if analyse_3d else HistMaker1d\n",
    "\n",
    "bins = Bins.readFrom(\"ranges.yml\")\n",
    "#histMakerData_np = HistMakerClass(\"apr12_diele_088_090_ag123ag_2500A_accepted_np_mix_hc_sample_2.dat\", \"_data\", bins, frame)\n",
    "if event_mixing:\n",
    "    histMakerData_np = HistMakerClass(filename_data_np_mix, \"_data_np\", bins, frame, ekin)\n",
    "else:\n",
    "    histMakerData_np = HistMakerClass(filename_data_np, \"_data_np\", bins, frame, ekin)\n",
    "histsData_np = histMakerData_np.make_hists  ()\n",
    "histMakerData_pp = HistMakerClass(filename_data_pp, \"_data_pp\", bins, frame, ekin)\n",
    "histsData_pp = histMakerData_pp.make_hists()\n",
    "histMakerData_nn = HistMakerClass(filename_data_nn, \"_data_nn\", bins, frame, ekin)\n",
    "histsData_nn = histMakerData_nn.make_hists()\n",
    "\n",
    "histMakerData_np_mix = HistMakerClass(filename_data_np_mix, \"_data_np_mix\", bins, frame, ekin)\n",
    "histsData_np_mix = histMakerData_np_mix.make_hists()\n",
    "histMakerData_pp_mix = HistMakerClass(filename_data_np_mix, \"_data_pp_mix\", bins, frame, ekin)\n",
    "histsData_pp_mix = histMakerData_pp_mix.make_hists()\n",
    "histMakerData_nn_mix = HistMakerClass(filename_data_nn_mix, \"_data_nn_mix\", bins, frame, ekin)\n",
    "histsData_nn_mix = histMakerData_nn_mix.make_hists()\n",
    "\n",
    "histMakerMC_rho_heli0_np = HistMakerClass(filename_MC_rho_heli0_np, \"_MC_rho_heli0\", bins, frame, ekin)\n",
    "histMakerMC_rho_heli0_pp = HistMakerClass(filename_MC_rho_heli0_pp, \"_MC_rho_heli0_pp\", bins, frame, ekin)\n",
    "histMakerMC_rho_heli0_nn = HistMakerClass(filename_MC_rho_heli0_nn, \"_MC_rho_heli0_nn\", bins, frame, ekin)\n",
    "histMakerMC_rho_heli1 = HistMakerClass(filename_MC_rho_heli1, \"_MC_rho_heli1\", bins, frame, ekin)\n",
    "histMakerMC_pi0 = HistMakerClass(filename_MC_pi0, \"_MC_pi0\", bins, frame, ekin)\n",
    "histMakerMC_mix = HistMakerClass(filename_MC_mix, \"_MC_mix\", bins, frame, ekin)\n",
    "#histMakerMC_mix = HistMakerClass(\"test_inmedium_heli0cm_np_mix.dat\", \"_MC_rho_mix\", bins, frame)\n",
    "#histMakerMC_mix = HistMakerClass(\"mar19_diele_pi0_heli0cm_np_mix.dat\", \"_MC_rho_mix\", bins, frame)\n",
    "def get_hist_maker_mc(sign, hist_index):\n",
    "    if event_mixing:\n",
    "        return histMakerMC_mix\n",
    "    else:\n",
    "        if hist_index < 3:\n",
    "            return CombinedHistMaker(histMakerMC_pi0, histMakerMC_rho_heli0_np, fraction)\n",
    "        else:\n",
    "            if sign == \"np\":\n",
    "                return histMakerMC_rho_heli0_np\n",
    "            elif sign == \"pp\":\n",
    "                return histMakerMC_rho_heli0_pp\n",
    "            else:\n",
    "                return histMakerMC_rho_heli0_nn\n",
    "        # return histMakerMC_rho_heli0_np"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-01-12T15:01:31.880034Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "torch.backends.mps.is_available()\n",
    "#mps_device = torch.device(\"mps\")\n",
    "mps_device = torch.device(\"cpu\")\n",
    "bounds = torch.tensor([[-2, ],\n",
    "                       [ 2, ]], dtype=torch.float)\n",
    "bounds = bounds.to(mps_device)\n",
    "\n",
    "\n",
    "xs = torch.linspace(bounds[0][0], bounds[1][0], 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "parameters_all_np = []\n",
    "losses_all_np = [[]]* len(range_used)\n",
    "\n",
    "fit_simple = helicity_model_3d.fit_simple if analyse_3d else helicity_model_1d.fit_simple\n",
    "\n",
    "for HIST_INDEX in range_used:\n",
    "    simple_model = helicity_model_3d.Helicity3d(learn_norm) if analyse_3d else helicity_model_1d.Helicity1d(learn_norm)\n",
    "    hist_data_simple = histsData_np[0][HIST_INDEX]\n",
    "    hist_mc_simple = get_hist_maker_mc(\"np\", HIST_INDEX).make_hists(0.0)[0][HIST_INDEX]\n",
    "    if HIST_INDEX == 2:\n",
    "        losses = fit_simple(simple_model, hist_data_simple, hist_mc_simple, 1000, 0.01, learn_norm)\n",
    "    else:\n",
    "        losses = fit_simple(simple_model, hist_data_simple, hist_mc_simple, 1000, 0.01, learn_norm)\n",
    "    parameters_all_np.append([param for param in simple_model.parameters()])\n",
    "    losses_all_np[HIST_INDEX] = losses\n",
    "    \n",
    "parameters_all_pp = []\n",
    "losses_all_pp = [[]]* len(range_used)\n",
    "\n",
    "for HIST_INDEX in range_used:\n",
    "    simple_model = helicity_model_3d.Helicity3d(learn_norm) if analyse_3d else helicity_model_1d.Helicity1d(learn_norm)\n",
    "    hist_data_simple = histsData_pp[0][HIST_INDEX]\n",
    "    hist_mc_simple = get_hist_maker_mc(\"pp\", HIST_INDEX).make_hists(0.0)[0][HIST_INDEX]\n",
    "    losses = fit_simple(simple_model, hist_data_simple, hist_mc_simple, 10000, 0.01, learn_norm)\n",
    "    parameters_all_pp.append([param for param in simple_model.parameters()])\n",
    "    losses_all_pp[HIST_INDEX] = losses\n",
    "    \n",
    "parameters_all_nn = []\n",
    "losses_all_nn = [[]]* len(range_used)\n",
    "\n",
    "for HIST_INDEX in range_used:\n",
    "    simple_model = helicity_model_3d.Helicity3d(learn_norm) if analyse_3d else helicity_model_1d.Helicity1d(learn_norm)\n",
    "    hist_data_simple = histsData_nn[0][HIST_INDEX]\n",
    "    hist_mc_simple = get_hist_maker_mc(\"nn\", HIST_INDEX).make_hists(0.0)[0][HIST_INDEX]\n",
    "    losses = fit_simple(simple_model, hist_data_simple, hist_mc_simple, 10000, 0.01, learn_norm)\n",
    "    parameters_all_nn.append([param for param in simple_model.parameters()])\n",
    "    losses_all_nn[HIST_INDEX] = losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "fig_np, ax_np = plot_losses(losses_all_np, range_used)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Calculating covariance matrix for parameters\n",
    "\n",
    "In general, if the value of the fitted model with $m$ parameters at point $x_i$ can be expressed as ({cite}`@cowan1998statistical`):\n",
    "$$f(x_i,\\mathbf{\\lambda})=\\sum_{j=1}^{m}a_j(x_i)\\lambda_j\\equiv\\sum_{j=1}^{m}A_{ij}\\lambda_j,$$\n",
    "then the expression for $\\chi^2$ is:\n",
    "$$\\chi^2=(\\mathbf{y}-A\\mathbf{\\lambda})^T V^{-1}(\\mathbf{y}-A\\mathbf{\\lambda}),$$\n",
    "where $V$ is the covariance matrix of different data points. We have only statistical errors at each data point (histogram bin in our case), so we assume, witn $n$ data points (bins),\n",
    "$$V^{-1}=\\mathrm{diag}\\left(\\frac{1}{\\sigma^2_{1}},\\frac{1}{\\sigma^2_{2}},\\frac{1}{\\sigma^2_{3}},...,\\frac{1}{\\sigma^2_{n}}\\right).$$\n",
    "The covariance matrix for for parameters, $U_{ij}=\\mathrm{cov}[\\hat{\\lambda}_i,\\hat{\\lambda}_j]$ is calculated as\n",
    "$$U=(A^TV^{-1}A)^{-1}.$$\n",
    "In our case, the $i$-th row of matrix $A$, corresponding to the $i$-th data point (bin) has the following form:\n",
    "$$\\left(\\frac{c_i}{I}\\;\\;\\;\\frac{c_i}{I}\\cos^2(\\theta_i)\\;\\;\\;\\frac{c_i}{I}\\sin(2\\theta_i)cos(\\phi_i)\\;\\;\\;\\frac{c_i}{I}\\sin^2(\\theta_i)\\cos(2\\phi_i)\\right),$$\n",
    "where $\\theta_i$, $\\phi_i$ are values corresponding the bin center. Note, that one of the axes is $\\cos(\\theta)$, so $\\arccos$ has to be calculated. $c_i$ is the bin content of the **unweighted** model histogram. $I$ is the integral of the model histogram **after applying the weights**. Thanks to that, the weighted histogram is always normalized to unity and can be compared to the experimental data histogram ($\\mathbf{y}$) which is also normalized to unity all the time.\n",
    "\n",
    "For the errors of the fit parameters, we just use square roots of the diagonal elements of the matrix $U$. However, with the matrix $A$ given above, we calculate the covariance matrix for the fit:\n",
    "$$f(\\theta,\\phi)=A+B\\cos^2(\\theta_i)+C\\sin(2\\theta_i)cos(\\phi_i)+D\\sin^2(\\theta_i)\\cos(2\\phi_i).$$\n",
    "In order to get correct errors of the parameters of the fit:\n",
    "$$f(\\theta,\\phi)\\propto1+\\lambda_\\theta\\cos^2(\\theta_i)+\\lambda_{\\theta\\phi}\\sin(2\\theta_i)cos(\\phi_i)+\\lambda_\\phi\\sin^2(\\theta_i)\\cos(2\\phi_i),$$\n",
    "we use error propagation to calculate the errors of ratios of ${B, C, D}$ parameters to $A$.\n",
    "\n",
    "{bibliography}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "show_results(\"np\", DIR_NAME, range_used, parameters_all_np, get_hist_maker_mc, bins, histsData_np, analyse_3d)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig_pp, ax_pp = plot_losses(losses_all_pp, range_used)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "show_results(\"pp\", DIR_NAME, range_used, parameters_all_pp, get_hist_maker_mc, bins, histsData_pp, analyse_3d)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig_nn, ax_nn = plot_losses(losses_all_nn, range_used)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "show_results(\"nn\", DIR_NAME, range_used, parameters_all_nn, get_hist_maker_mc, bins, histsData_nn, analyse_3d)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if not analyse_3d:\n",
    "    histsDataCorrs = []\n",
    "    histsDatas = []\n",
    "    histsModels = []\n",
    "    legends = []\n",
    "    hmodel_null = histMakerMC_rho_heli0_np.make_hists((0.0))\n",
    "    hmodel_null_pp = histMakerMC_rho_heli0_pp.make_hists((0.0))\n",
    "    hmodel_null_nn = histMakerMC_rho_heli0_nn.make_hists((0.0))\n",
    "    hmodel_null_mix = histMakerMC_mix.make_hists((0.0))\n",
    "    hmodel_null_pi0 = histMakerMC_pi0.make_hists((0.0))\n",
    "    hmodel_null_heli1 = histMakerMC_rho_heli1.make_hists((0.0))\n",
    "\n",
    "    pol2s = []\n",
    "    histsAvg = []\n",
    "    kfactors = []\n",
    "\n",
    "    cc4 = TCanvas(\"cc4\",\"cc4\",900,1200)\n",
    "    cc4.Divide(3,4)\n",
    "    cc4.Draw()\n",
    "\n",
    "    cck = TCanvas(\"cck\",\"cck\",900,1200)\n",
    "    cck.Divide(3,4)\n",
    "\n",
    "    csig = TCanvas(\"csig\",\"csig\",900,1200)\n",
    "    csig.Divide(3,4)\n",
    "\n",
    "    cacc = TCanvas(\"cacc\",\"cacc\",900,1200)\n",
    "    cacc.Divide(3,4)\n",
    "\n",
    "    for i, hist_np in enumerate(histsData_np[0]):\n",
    "    \n",
    "        if not isinstance(hist_np, list):\n",
    "\n",
    "            hist_pp = histsData_pp[0][i]\n",
    "            hist_nn = histsData_nn[0][i]\n",
    "        \n",
    "            if symmetrize_explicit:\n",
    "                symmetrize(hist_np)\n",
    "                symmetrize(hist_pp)\n",
    "                symmetrize(hist_nn)\n",
    "        \n",
    "            histAvg = geom_avg1d(hist_pp, hist_nn, 0.2)\n",
    "            histsAvg.append(histAvg)\n",
    "\n",
    "        \n",
    "            histCorr_np = hist_np.Clone(hist_np.GetName() + \"_corr\")\n",
    "            histCorr_pp = hist_pp.Clone(hist_pp.GetName() + \"_corr\")\n",
    "            histCorr_nn = hist_nn.Clone(hist_nn.GetName() + \"_corr\")\n",
    "            histsDataCorrs.append(histCorr_np)\n",
    "            histsDataCorrs.append(histCorr_pp)\n",
    "            histsDataCorrs.append(histCorr_nn)\n",
    "            histCorr_np.GetXaxis().SetTitle(\"cos(#theta_{e}^{#gamma*})\")\n",
    "        \n",
    "            pad = cc4.cd(i+1)\n",
    "            set_pad(pad)       \n",
    "       \n",
    "            hist_kfactor = histsData_np_mix[0][i]\n",
    "            hist_pp_mix = histsData_pp_mix[0][i]\n",
    "            hist_nn_mix = histsData_nn_mix[0][i]\n",
    "\n",
    "            if symmetrize_explicit:\n",
    "                symmetrize(hist_kfactor)\n",
    "                symmetrize(hist_pp_mix)\n",
    "                symmetrize(hist_nn_mix)\n",
    "\n",
    "            histAvg_mix = geom_avg1d(hist_pp_mix, hist_nn_mix, 0.2)\n",
    "            hist_kfactor.Divide(histAvg_mix)\n",
    "            hist_kfactor.Scale(2)\n",
    "            kfactors.append(hist_kfactor)\n",
    "\n",
    "            pad = cck.cd(i+1)\n",
    "            set_pad(pad)\n",
    "\n",
    "            hist_kfactor.GetXaxis().SetTitle(\"cos(#theta_{e}^{#gamma*})\")\n",
    "        \n",
    "            set_th1(hist_kfactor, histCorr_np.GetXaxis().GetTitle(), \"#it{k}-factor\", \n",
    "                   505, 20, 0.8, 1)\n",
    "            hist_pp_mix.SetLineColor(2)\n",
    "            hist_nn_mix.SetLineColor(4)\n",
    "            hist_pp_mix.SetMarkerColor(2)\n",
    "            hist_nn_mix.SetMarkerColor(4)\n",
    "            hist_kfactor.Draw()\n",
    "            hist_pp_mix.Draw(\"SAME\")\n",
    "            hist_nn_mix.Draw(\"SAME\")\n",
    "            hist_kfactor.SetMinimum(0)\n",
    "             \n",
    "            pad = cc4.cd(i+1)\n",
    "            set_pad(pad)       \n",
    "            \n",
    "            histAvg_withK = histAvg.Clone(histAvg.GetName() + \"_withK\")\n",
    "            histsAvg.append(histAvg_withK)\n",
    "            histAvg_withK.Multiply(hist_kfactor)\n",
    "            \n",
    "            histAvg_withK.SetFillStyle(3004)\n",
    "            histAvg_withK.SetFillColor(45)\n",
    "            histAvg_withK.SetLineColor(45)\n",
    "            histAvg.SetLineColor(6)\n",
    "            hist_pp.SetLineColor(4)\n",
    "            hist_nn.SetLineColor(2)\n",
    "                    \n",
    "            set_th1(hist_np, histCorr_np.GetXaxis().GetTitle(), f\"dN/d{histCorr_np.GetXaxis().GetTitle()} (a.u.)\", \n",
    "                   505, 20, 0.8, 1)\n",
    "            hist_np.SetMinimum(0)\n",
    "            hist_np.Draw()\n",
    "            histAvg_withK.Draw(\"SAMEHIST\")\n",
    "            histAvg.Draw(\"SAMEHIST\")\n",
    "            hist_pp.Draw(\"SAMEHIST\")\n",
    "            hist_nn.Draw(\"SAMEHIST\")\n",
    "            \n",
    "            pad = csig.cd(i+1)\n",
    "            set_pad(pad)     \n",
    "    \n",
    "            hist_model_np = hmodel_null_mix[0][i]\n",
    "            # TODO: make it consistent if we go the way of using mixing\n",
    "            hist_model_pp = hmodel_null_mix[0][i]\n",
    "            hist_model_nn = hmodel_null_mix[0][i]\n",
    "            if not event_mixing:\n",
    "                if i < 3:\n",
    "                    hist_model_np = hmodel_null_pi0[0][i]\n",
    "                    # TODO: make is consisnt if combinatorial background really matters for the pi0 region\n",
    "                    hist_model_pp = hmodel_null_pi0[0][i]\n",
    "                    hist_model_nn = hmodel_null_pi0[0][i]\n",
    "                else:\n",
    "                    hist_model_np = hmodel_null[0][i]\n",
    "                    hist_model_pp = hmodel_null_pp[0][i]\n",
    "                    hist_model_nn = hmodel_null_nn[0][i]\n",
    "            if symmetrize_explicit:\n",
    "                symmetrize(hist_model_np)\n",
    "    \n",
    "           # histCorr_np.Add(histAvg_withK,-1)\n",
    "            histCorr_np.Divide(hist_model_np)\n",
    "            histCorr_pp.Divide(hist_model_pp)\n",
    "            histCorr_nn.Divide(hist_model_nn)\n",
    "            \n",
    "            histAvgCorr = geom_avg1d(histCorr_pp, histCorr_nn, 0.2)\n",
    "            histsAvg.append(histAvgCorr)\n",
    "            histAvgCorr_withK = histAvgCorr.Clone(histAvgCorr.GetName() + \"_withK\")\n",
    "            histsAvg.append(histAvgCorr_withK)\n",
    "            histAvgCorr_withK.Multiply(hist_kfactor)\n",
    "        \n",
    "            s2b = (hist_np.Integral() - histAvg_withK.Integral()) / histAvg_withK.Integral()\n",
    "            s2b_corr = (histCorr_np.Integral() - histAvgCorr_withK.Integral()) / histAvgCorr_withK.Integral()\n",
    "            histCorr_pp.Scale(s2b/s2b_corr)\n",
    "            histCorr_nn.Scale(s2b/s2b_corr)\n",
    "            histAvgCorr.Scale(s2b/s2b_corr)\n",
    "            histAvgCorr_withK.Scale(s2b/s2b_corr)\n",
    "        \n",
    "            histAvgCorr_withK.SetFillStyle(3004)\n",
    "            histAvgCorr_withK.SetFillColor(45)\n",
    "            histAvgCorr_withK.SetLineColor(45)\n",
    "            histAvgCorr.SetLineColor(6)\n",
    "    \n",
    "            #if symmetrize_explicit:    \n",
    "                #symmetrize(histCorr_np)\n",
    "    \n",
    "            fit = TF1(f\"fit_{i}\", \"[0]*(1+[1]*x*x)\",-1.0,1.0)\n",
    "            fit.SetParameters(1, 1)\n",
    "            \n",
    "            histCorr_np.Fit(fit,\"Q\")\n",
    "            pol2s.append(fit)\n",
    "        \n",
    "            set_th1(histCorr_np, histCorr_np.GetXaxis().GetTitle(), f\"dN/d{histCorr_np.GetXaxis().GetTitle()} (a.u.)\", \n",
    "                   505, 20, 0.8, 1)\n",
    "        \n",
    "            histCorr_pp.SetLineColor(4)\n",
    "            histCorr_nn.SetLineColor(2)\n",
    "            histCorr_np.Draw()\n",
    "            histCorr_pp.Draw(\"SAMEHIST\")\n",
    "            histCorr_nn.Draw(\"SAMEHIST\")\n",
    "            histAvgCorr.Draw(\"SAMEHIST\")\n",
    "            histAvgCorr_withK.Draw(\"SAMEHIST\")\n",
    "            if i < 3:\n",
    "                # histCorr_np.GetYaxis().SetRangeUser(0,2.5)\n",
    "                histCorr_np.GetYaxis().SetRangeUser(0,20)\n",
    "            else:\n",
    "                # histCorr_np.GetYaxis().SetRangeUser(0,1.25)    \n",
    "                histCorr_np.GetYaxis().SetRangeUser(0,2)    \n",
    "            histCorr_np.SetMinimum(0)\n",
    "            \n",
    "            caption = f\"#lambda_{{#theta}} = {fit.GetParameter(1):.2f} #pm {fit.GetParError(1):.2f}\"\n",
    "            paveText = set_opt_text(caption, 0.25,0.76,0.675,0.88, 2, 0.04)\n",
    "            paveTexts.append(paveText)\n",
    "    \n",
    "            if i == 4:\n",
    "                l = TLegend(0.3,0.45,0.8,0.8)\n",
    "                l.SetBorderSize(0)\n",
    "                l.AddEntry(histCorr_np,\"e+e- pairs\",\"pl\")\n",
    "                l.AddEntry(histCorr_pp,\"e+e+ pairs\",\"l\")\n",
    "                l.AddEntry(histCorr_nn,\"e-e- pairs\",\"l\")\n",
    "                l.AddEntry(histAvgCorr,\"geom. mena\",\"pl\")\n",
    "                l.AddEntry(histAvgCorr_withK,\"geom. mena with k-factor\",\"pl\")\n",
    "                l.Draw()\n",
    "                legends.append(l)\n",
    "            \n",
    "    \n",
    "            pad = cacc.cd(i+1)\n",
    "            set_pad(pad)\n",
    "            \n",
    "            hacc_heli0 = hmodel_null[0][i]\n",
    "            hacc_heli1 = hmodel_null_heli1[0][i]\n",
    "    \n",
    "        else:\n",
    "            print(hist_np)\n",
    "    \n",
    "    cc4.SaveAs(f\"{DIR_NAME}/fit_classic.gif\")\n",
    "    cc4.SaveAs(f\"{DIR_NAME}/fit_classic.pdf\")\n",
    "        \n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if not analyse_3d:\n",
    "    cck.Draw()\n",
    "    cck.SaveAs(f\"{DIR_NAME}/kfactor.gif\")\n",
    "    \n",
    "    csig.Draw()\n",
    "    csig.SaveAs(f\"{DIR_NAME}/signal.gif\")\n",
    "    csig.SaveAs(f\"{DIR_NAME}/signal.eps\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "can_mass_z_np = show_mass_z(histsData_np, histMakerMC_pi0, histMakerMC_rho_heli0_np, histMakerMC_mix, event_mixing, fraction, DIR_NAME, \"np\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "can_mass_z_pp = show_mass_z(histsData_pp, histMakerMC_pi0, histMakerMC_rho_heli0_pp, histMakerMC_mix, event_mixing, fraction, DIR_NAME, \"pp\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "can_mass_z_np = show_mass_z(histsData_nn, histMakerMC_pi0, histMakerMC_rho_heli0_nn, histMakerMC_mix, event_mixing, fraction, DIR_NAME, \"nn\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if not analyse_3d:\n",
    "    cacc.Draw()\n",
    "    cacc.SaveAs(f\"{DIR_NAME}/cacc.gif\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
