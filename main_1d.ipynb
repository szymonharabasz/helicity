{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T15:31:49.804714Z",
     "start_time": "2023-11-06T15:31:45.584639Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.28/04\n"
     ]
    }
   ],
   "source": [
    "# %env PYTORCH_ENABLE_MPS_FALLBACK=1\n",
    "%load_ext autoreload\n",
    "%autoreload\n",
    "\n",
    "from bins import Bins\n",
    "from utils import calcOneChi2, HistMaker_1d, diffHist, setOPT_text, setTH1, setPad, geomAvg1d\n",
    "from ROOT import TFile, TH1, TH3F, TF2, TF1, TCanvas, TStyle, gStyle, Form, Fit, TLegend\n",
    "import scipy.optimize as opt\n",
    "import math\n",
    "import calendar, os\n",
    "from time import time, gmtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T15:31:50.046471Z",
     "start_time": "2023-11-06T15:31:49.809254Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ag1580ag' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 14\u001B[0m\n\u001B[1;32m     12\u001B[0m         DIR_NAME \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mresults_mixing_nu15_noise1em1_1d\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 14\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[43mag1580ag\u001B[49m:\n\u001B[1;32m     15\u001B[0m         DIR_NAME \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mresults_sameevt_nu15_noise1em1_1d_ag1580ag\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     16\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[0;31mNameError\u001B[0m: name 'ag1580ag' is not defined"
     ]
    }
   ],
   "source": [
    "gStyle.SetOptStat(0)\n",
    "\n",
    "event_mixing = False\n",
    "read_saved = True\n",
    "range_used = range(0,12)\n",
    "\n",
    "if read_saved:\n",
    "    if event_mixing:\n",
    "        if ag1580ag:\n",
    "            DIR_NAME = \"results_mixing_nu15_noise1em1_1d_ag1580ag\"\n",
    "        else:\n",
    "            DIR_NAME = \"results_mixing_nu15_noise1em1_1d\"\n",
    "    else:\n",
    "        if ag1580ag:\n",
    "            DIR_NAME = \"results_sameevt_nu15_noise1em1_1d_ag1580ag\"\n",
    "        else:\n",
    "            DIR_NAME = \"results_sameevt_nu15_noise1em1_1d\"\n",
    "else:\n",
    "    current_GMT =   gmtime()\n",
    "    time_stamp = calendar.timegm(current_GMT)\n",
    "    DIR_NAME = f'results_{time_stamp}'\n",
    "    os.mkdir(DIR_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T15:31:50.052889Z",
     "start_time": "2023-11-06T15:31:50.048618Z"
    }
   },
   "outputs": [],
   "source": [
    "ag1580ag = True\n",
    "\n",
    "if ag1580ag:\n",
    "    filename_data_np = \"063_088_ag158ag_3200A_accepted_np.dat\"\n",
    "    filename_data_pp = \"063_088_ag158ag_3200A_accepted_pp.dat\"\n",
    "    filename_data_nn = \"063_088_ag158ag_3200A_accepted_nn.dat\"\n",
    "    filename_data_np_mix = \"063_088_ag158ag_3200A_accepted_np_mix_hc.dat\"\n",
    "    filename_data_pp_mix = \"apr12_diele_086_ag158ag_3200A_accepted_1_pp_mix_hc.dat\"\n",
    "    filename_data_nn_mix = \"apr12_diele_086_ag158ag_3200A_accepted_1_nn_mix_hc.dat\"\n",
    "    filename_MC_rho = \"mar19_diele_inmedium_heli0cm_ag1580ag_np.dat\"\n",
    "    filename_MC_pi0 = \"mar19_diele_pi0_heli0cm_ag1580ag_np.dat\"\n",
    "    filename_MC_mix = \"mar19_diele_pi0_heli0cm_ag1580ag_np_mix.dat\"\n",
    "else:\n",
    "    filename_data_np = \"apr12_diele_088_090_ag123ag_2500A_accepted_np_2.dat\"\n",
    "    filename_data_pp = \"088_090_ag123ag_2500A_accepted_pp.dat\"\n",
    "    filename_data_nn = \"088_090_ag123ag_2500A_accepted_nn.dat\"\n",
    "    filename_data_np_mix = \"088_090_ag123ag_2500A_accepted_np_mix_hc.dat\"\n",
    "    filename_data_pp_mix = \"088_090_ag123ag_2500A_accepted_pp_mix_hc.dat\"\n",
    "    filename_data_nn_mix = \"088_090_ag123ag_2500A_accepted_nn_mix_hc.dat\"\n",
    "    filename_MC_rho = \"mar19_diele_inmedium_heli0cm_np.dat\"\n",
    "    filename_MC_pi0 = \"mar19_diele_pi0_heli0cm_ag1580ag_np.dat.dat\"\n",
    "    filename_MC_mix = \"mar19_diele_pi0_heli0cm_np_mix.dat\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "bins = Bins.readFrom(\"ranges.yml\")\n",
    "#histMakerData_np = HistMaker_1d(\"apr12_diele_088_090_ag123ag_2500A_accepted_np_mix_hc_sample_2.dat\", \"_data\", bins)\n",
    "if event_mixing:\n",
    "    histMakerData_np = HistMaker_1d(filename_data_np_mix, \"_data_np\", bins)\n",
    "else:\n",
    "    histMakerData_np = HistMaker_1d(filename_data_np, \"_data_np\", bins)\n",
    "histsData_np = histMakerData_np.makeHists()\n",
    "histMakerData_pp = HistMaker_1d(filename_data_pp, \"_data_pp\", bins)\n",
    "histsData_pp = histMakerData_pp.makeHists()\n",
    "histMakerData_nn = HistMaker_1d(filename_data_nn, \"_data_nn\", bins)\n",
    "histsData_nn = histMakerData_nn.makeHists()\n",
    "\n",
    "histMakerData_np_mix = HistMaker_1d(filename_data_np_mix, \"_data_pp_mix\", bins)\n",
    "histsData_np_mix = histMakerData_np_mix.makeHists()\n",
    "histMakerData_pp_mix = HistMaker_1d(filename_data_np_mix, \"_data_pp_mix\", bins)\n",
    "histsData_pp_mix = histMakerData_pp_mix.makeHists()\n",
    "histMakerData_nn_mix = HistMaker_1d(filename_data_nn_mix, \"_data_nn_mix\", bins)\n",
    "histsData_nn_mix = histMakerData_nn_mix.makeHists()\n",
    "\n",
    "histMakerMC_rho = HistMaker_1d(filename_MC_rho, \"_MC_rho\", bins)\n",
    "histMakerMC_pi0 = HistMaker_1d(filename_MC_pi0, \"_MC_pi0\", bins)\n",
    "histMakerMC_mix = HistMaker_1d(filename_MC_mix, \"_MC_mix\", bins)\n",
    "#histMakerMC_mix = HistMaker_1d(\"test_inmedium_heli0cm_np_mix.dat\", \"_MC_rho_mix\", bins)\n",
    "#histMakerMC_mix = HistMaker_1d(\"mar19_diele_pi0_heli0cm_np_mix.dat\", \"_MC_rho_mix\", bins)\n",
    "def getHistMakerMC(HIST_INDEX):\n",
    "    if event_mixing:\n",
    "        return histMakerMC_mix\n",
    "    else:\n",
    "        return histMakerMC_pi0 if HIST_INDEX < 3 else histMakerMC_rho\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "base_hists_pi0 = histMakerMC_pi0.builder.base_hists\n",
    "can3 = TCanvas(\"can3\",\"can3\",900,300)\n",
    "can3.Divide(3,1)\n",
    "can3.Draw()\n",
    "for i, hist in enumerate(base_hists_pi0[0]):\n",
    "    if i < 3:\n",
    "        pad = can3.cd(i+1)\n",
    "        setPad(pad)\n",
    "\n",
    "        if not isinstance(hist, list):\n",
    "            hist.GetXaxis().SetTitle(\"cos(#theta_{e}^{#gamma*})\")\n",
    "            setTH1(hist, hist.GetXaxis().GetTitle(), f\"dN/d{hist.GetXaxis().GetTitle()} (a.u.)\", \n",
    "               505, 20, 0.8, 1)\n",
    "            hist.Draw()\n",
    "        else:\n",
    "            print(hist)\n",
    "can3.SaveAs(f\"{DIR_NAME}/base_hists_pi0_MC.gif\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-06T15:31:50.050192Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-06T15:31:50.051386Z"
    }
   },
   "outputs": [],
   "source": [
    "base_hists_rho = histMakerMC_rho.builder.base_hists\n",
    "can5 = TCanvas(\"can5\",\"can5\",900,1200)\n",
    "can5.Divide(3,4)\n",
    "can5.Draw()\n",
    "for i, hist in enumerate(base_hists_rho[0]):\n",
    "    pad = can5.cd(i+1)\n",
    "    setPad(pad)\n",
    "    if not isinstance(hist, list):\n",
    "        hist.GetXaxis().SetTitle(\"cos(#theta_{e}^{#gamma*})\")\n",
    "        setTH1(hist, hist.GetXaxis().GetTitle(), f\"dN/d{hist.GetXaxis().GetTitle()} (a.u.)\", \n",
    "               505, 20, 0.8, 1)\n",
    "        hist.Draw()\n",
    "    else:\n",
    "        print(hist)\n",
    "can5.SaveAs(f'{DIR_NAME}/base_hists_rho_MC.gif')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-06T15:31:50.052439Z"
    }
   },
   "outputs": [],
   "source": [
    "can4 = TCanvas(\"can4\",\"can4\",900,1200)\n",
    "can4.Divide(3,4)\n",
    "can4.Draw()\n",
    "for i, hist in enumerate(histsData_np[0]):\n",
    "    pad = can4.cd(i+1)\n",
    "    setPad(pad)\n",
    "    if not isinstance(hist, list):\n",
    "        hist.GetXaxis().SetTitle(\"cos(#theta_{e}^{#gamma*})\")\n",
    "        setTH1(hist, hist.GetXaxis().GetTitle(), f\"dN/d{hist.GetXaxis().GetTitle()} (a.u.)\", \n",
    "               505, 20, 0.8, 1)\n",
    "        hist.Draw()\n",
    "    else:\n",
    "        print(hist)\n",
    "\n",
    "can4.SaveAs(f'{DIR_NAME}/histsData_np.gif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-06T15:31:50.053536Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.device(\"mps\")\n",
    "torch.manual_seed(0)\n",
    "\n",
    "import gpytorch\n",
    "import botorch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use(\"bmh\")\n",
    "plt.rcParams[\"figure.figsize\"] = (8, 6)\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T15:31:50.055351Z",
     "start_time": "2023-11-06T15:31:50.054287Z"
    }
   },
   "outputs": [],
   "source": [
    "TH1.SetDefaultSumw2\n",
    "\n",
    "gpytorch.settings.fast_pred_var()\n",
    "gpytorch.settings.fast_pred_samples()\n",
    "\n",
    "N_PARAMS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T15:31:50.055789Z",
     "start_time": "2023-11-06T15:31:50.055426Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.backends.mps.is_available()\n",
    "#mps_device = torch.device(\"mps\")\n",
    "mps_device = torch.device(\"cpu\")\n",
    "bounds = torch.tensor([[-1, ],\n",
    "                       [ 1, ]], dtype=torch.float)\n",
    "bounds = bounds.to(mps_device)\n",
    "\n",
    "\n",
    "xs = torch.linspace(bounds[0][0], bounds[1][0], 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-06T15:31:50.056653Z"
    }
   },
   "outputs": [],
   "source": [
    "class GPModel(gpytorch.models.ExactGP, botorch.models.gpytorch.GPyTorchModel):\n",
    "# class GPModel(gpytorch.models.ApproximateGP, botorch.models.gpytorch.GPyTorchModel):\n",
    "    _num_outputs = 1\n",
    "\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super().__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(\n",
    "            gpytorch.kernels.MaternKernel(nu=1.5, ard_num_dims=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        mean_x = mean_x.to(mps_device)\n",
    "        covar_x = covar_x.to(mps_device)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "def fit_gp_model(train_x, train_y, num_train_iters=500):\n",
    "    train_x = train_x.to(mps_device)\n",
    "    train_y = train_y.to(mps_device)\n",
    "\n",
    "    # declare the GP\n",
    "    noise = 1e-1\n",
    "\n",
    "    likelihood = gpytorch.likelihoods.StudentTLikelihood()\n",
    "    likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "    model = GPModel(train_x, train_y, likelihood)\n",
    "    model.likelihood.noise = noise\n",
    "    likelihood = likelihood.to(mps_device)\n",
    "    model = model.to(mps_device)\n",
    "\n",
    "    # train the hyperparameter (the constant)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "    model.train()\n",
    "    likelihood.train()\n",
    "\n",
    "    for i in range(num_train_iters):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(train_x)\n",
    "        loss = -mll(output, train_y)\n",
    "\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    likelihood.eval()\n",
    "\n",
    "    return model.cpu(), likelihood.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-06T15:31:50.057412Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Come back to standard version\n",
    "#num_queries = 75\n",
    "num_queries = 200\n",
    "num_repeats = 1\n",
    "num_samples = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-06T15:31:50.058134Z"
    }
   },
   "outputs": [],
   "source": [
    "# -2 is the default value when no feasible has been found\n",
    "default_value = -1\n",
    "\n",
    "def fit_bo(HIST_INDEX = 0):\n",
    "    global bounds\n",
    "\n",
    "    def objective(xx):\n",
    "        def generator(xx):\n",
    "            for x in xx:\n",
    "                lambda_theta = x\n",
    "\n",
    "                histsMC = getHistMakerMC(HIST_INDEX).makeHists(lambda_theta)\n",
    "                chi2, ndf = calcOneChi2(histsMC[0][HIST_INDEX], histsData_np[0][HIST_INDEX])\n",
    "                allHistsMC.append(histsMC[0][HIST_INDEX])\n",
    "                if not chi2 or not ndf:\n",
    "                    return torch.tensor([0])\n",
    "                yield torch.tensor([1.0/(chi2 / ndf)])\n",
    "        return torch.stack([a for a in generator(xx)])\n",
    "\n",
    "    def one_starting_sample():\n",
    "        result = bounds[0] + (bounds[1] - bounds[0]) * torch.rand(N_PARAMS)\n",
    "        return result\n",
    "\n",
    "    feasible_incumbents = torch.ones((num_repeats, num_queries)) * default_value\n",
    "\n",
    "    best_fs = []\n",
    "\n",
    "    print(f\"HIST INDEX: {HIST_INDEX}\")\n",
    "    for trial in range(num_repeats):\n",
    "       # print(\"trial\", trial)\n",
    "\n",
    "        torch.manual_seed(trial)\n",
    "       # train_x = bounds[0] + (bounds[1] - bounds[0]) * torch.rand(num_samples, 3)\n",
    "       # while -2.0*train_x[0][0] - 1.0*train_x[0][2] < -2:\n",
    "       #     train_x = bounds[0] + (bounds[1] - bounds[0]) * torch.rand(num_samples, 3)\n",
    "        train_x = torch.stack([one_starting_sample() for _ in range(num_samples)])\n",
    "        train_utility = objective(train_x).to(mps_device)\n",
    "        train_x = train_x.to(mps_device)\n",
    "\n",
    "        for i in tqdm(range(num_queries)):\n",
    "            feasible_incumbents[trial, i] = train_utility.max()\n",
    "            before_fit_gp = time()\n",
    "            utility_model, utility_likelihood = fit_gp_model(\n",
    "                train_x, train_utility.squeeze(-1)\n",
    "            )\n",
    "            after_fit_gp = time()\n",
    "           # print(\"Fitting GP took \" + str(after_fit_gp - before_fit_gp) + \" seconds\")\n",
    "            best_f = train_utility.max()\n",
    "            best_fs.append(best_f.item())\n",
    "                \n",
    "           # policy = botorch.acquisition.monte_carlo.qExpectedImprovement(\n",
    "           # policy = botorch.acquisition.analytic.LogExpectedImprovement(\n",
    "            policy = botorch.acquisition.logei.qLogExpectedImprovement(\n",
    "          # policy = botorch.acquisition.analytic.LogProbabilityOfImprovement(\n",
    "          # policy = botorch.acquisition.analytic.PosteriorMean(\n",
    "                model=utility_model,\n",
    "                best_f=train_utility.max(),\n",
    "            ).to(mps_device)\n",
    "\n",
    "            before_optimize_acqf = time()\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.filterwarnings('ignore', category=RuntimeWarning)\n",
    "                next_x, acq_val = botorch.optim.optimize_acqf(\n",
    "                    policy,\n",
    "                    bounds=bounds,\n",
    "                    #q=5,\n",
    "                    #num_restarts=5,\n",
    "                    #raw_samples=400,\n",
    "                    q=1,\n",
    "                    num_restarts=40,\n",
    "                    raw_samples=100,\n",
    "                )\n",
    "            after_optimize_acqf = time()\n",
    "           # print(\"Optimizing ACQF took \" + str(after_optimize_acqf - before_optimize_acqf) + \" seconds\")\n",
    "\n",
    "            next_utility = objective(next_x).to(mps_device)\n",
    "\n",
    "            train_x = torch.cat([train_x, next_x])\n",
    "            train_utility = torch.cat([train_utility, next_utility])\n",
    "    torch.save(feasible_incumbents, f\"{DIR_NAME}/incumbents_\" + str(HIST_INDEX) + \".pth\")\n",
    "    fout = TFile(f\"{DIR_NAME}/out_{HIST_INDEX}.root\",\"RECREATE\")\n",
    "    fout.cd()\n",
    "    for hist in allHistsMC:\n",
    "       # print (\"Writing hist: \", hist.GetName())\n",
    "        hist.Write()\n",
    "    for j, hists in enumerate(histsData_np):\n",
    "        for k, hist in enumerate(hists):\n",
    "                hist.Write()\n",
    "               # print (\"Writing hist: \", j, k, hist)\n",
    "    fout.Close()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        predictive_distribution = utility_likelihood(utility_model(xs))\n",
    "        acquisition_score = policy(xs.unsqueeze(1))\n",
    "\n",
    "    lambda_thetas     = train_x.flatten()\n",
    "    \n",
    "    c = torch.stack((\n",
    "        torch.arange(0,num_queries, dtype=int),\n",
    "        lambda_thetas[0:num_queries],\n",
    "        train_utility.squeeze()[0:num_queries],\n",
    "        (feasible_incumbents==feasible_incumbents.max())[0],\n",
    "        feasible_incumbents[0]\n",
    "    ),0).transpose(-2,-1)\n",
    "    torch.set_printoptions(precision=4,threshold=10_000, linewidth=120)\n",
    "    sort_index = c[:, N_PARAMS + 1].sort()[1]\n",
    "    c_sorted = c[sort_index]\n",
    "    train_x_sorted = train_x[sort_index]\n",
    "\n",
    "    return c_sorted, train_x_sorted, predictive_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-06T15:31:50.060004Z"
    }
   },
   "outputs": [],
   "source": [
    "c_sorted_all = []\n",
    "train_x_sorted_all = []\n",
    "predictive_mean_all = []\n",
    "predictive_lower_all = []\n",
    "predictive_upper_all = []\n",
    "\n",
    "for HIST_INDEX in range_used:\n",
    "    allHistsMC = []\n",
    "    if read_saved:\n",
    "        c_sorted = torch.load(f\"{DIR_NAME}/c_sorted_\" + str(HIST_INDEX) + \".pth\")\n",
    "        train_x_sorted = torch.load(f\"{DIR_NAME}/train_x_sorted_\" + str(HIST_INDEX) + \".pth\")\n",
    "        predictive_distribution = torch.load(f\"{DIR_NAME}/predictive_distribution_\" + str(HIST_INDEX) + \".pth\")\n",
    "\n",
    "        file = TFile(f\"{DIR_NAME}/out_{HIST_INDEX}.root\", \"read\")\n",
    "        names = [key.GetName() for key in file.GetListOfKeys()]\n",
    "        names = [name for name in names if \"MC\" in name]\n",
    "        for name in names:\n",
    "            allHistsMC.append(file.Get(name))\n",
    "    else:\n",
    "        c_sorted, train_x_sorted, predictive_distribution = fit_bo(HIST_INDEX)\n",
    "        print(c_sorted[-5:])\n",
    "        \n",
    "        torch.save(c_sorted, f\"{DIR_NAME}/c_sorted_\" + str(HIST_INDEX) + \".pth\")\n",
    "        torch.save(train_x_sorted, f\"{DIR_NAME}/train_x_sorted_\" + str(HIST_INDEX) + \".pth\")\n",
    "        torch.save(predictive_distribution, f\"{DIR_NAME}/predictive_distribution_\" + str(HIST_INDEX) + \".pth\")\n",
    "\n",
    "    predictive_mean = predictive_distribution.mean\n",
    "    predictive_lower, predictive_upper = predictive_distribution.confidence_region()\n",
    "    print(\"AFTER_READING: \", predictive_mean[100], predictive_lower[100], predictive_upper[100])\n",
    "\n",
    "    c_sorted_all.append(c_sorted)\n",
    "    train_x_sorted_all.append(train_x_sorted)\n",
    "    predictive_mean_all.append(predictive_mean)\n",
    "    predictive_lower_all.append(predictive_lower)\n",
    "    predictive_upper_all.append(predictive_upper)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-06T15:31:50.060907Z"
    }
   },
   "outputs": [],
   "source": [
    "from ipywidgets import interact, Layout, IntSlider, FloatSlider\n",
    "import numpy as np\n",
    "\n",
    "axis_title = r\"$cos(\\theta_e^{\\gamma*})$\"\n",
    "\n",
    "def oneplot(ax, tensor, title):\n",
    "        \n",
    "        global xs\n",
    "        \n",
    "       # pos = ax.plot(xs, tensor, ymin=0, ymax=tensor.max())\n",
    "        pos = ax.plot(xs, tensor)\n",
    "       # ax.set_aspect((extent[1]-extent[0])/(extent[3]-extent[2]))\n",
    "        ax.set_title(title)\n",
    "        ax.set_xlabel(axis_title)\n",
    "\n",
    "can_cmp_ind = 0\n",
    "\n",
    "def plotComparison(can, pad_nr1, pad_nr2, histMC, histData, hist_index, pull_title):\n",
    "   # print(f\"PLOTTING: {histMC.GetName()} and {histData.GetName()}\")\n",
    "    global can_cmp_ind\n",
    "\n",
    "    curr_bin = bins[hist_index]\n",
    "    title = f\"{curr_bin.m_min} < #it{{M}}_{{ee}} < {curr_bin.m_max}, {curr_bin.z_min} < cos(#theta^{{CM}}_{{#gamma*}}) < {curr_bin.z_max}\"\n",
    "    \n",
    "    pad = can.cd(pad_nr1)\n",
    "    setPad(pad)\n",
    "    pad.SetRightMargin(0.16)\n",
    "    histData.GetXaxis().SetTitle(\"cos(#theta_{e}^{#gamma*})\")\n",
    "    histData.SetTitle(title)\n",
    "    setTH1(histData, histData.GetXaxis().GetTitle(), f\"dN/d{histData.GetXaxis().GetTitle()} (a.u.)\", \n",
    "               505, 20, 0.8, 1)\n",
    "    histData.Draw()\n",
    "    histMC.Scale(histData.Integral()/histMC.Integral())\n",
    "    histMC.SetLineColor(2)\n",
    "    histMC.Draw(\"SAMEHIST\")\n",
    "    pad = can.cd(pad_nr2)\n",
    "    setPad(pad)\n",
    "    pad.SetRightMargin(0.16)\n",
    "    hdiff = diffHist(histMC, histData)\n",
    "    hdiff.SetTitle(pull_title)\n",
    "    setTH1(hdiff, hdiff.GetXaxis().GetTitle(), \"Pull value\", 505, 20, 0.8, 2)\n",
    "    hdiff.Draw(\"HIST\")\n",
    "    can.Update()\n",
    "    can.Modified()\n",
    "    can.Update()\n",
    "    \n",
    "    return hdiff\n",
    "\n",
    "def countCommonNonZeroBins(histMC, histData):\n",
    "    n = 0\n",
    "    for i, j in zip(histMC, histData):\n",
    "        if i != 0 and j != 0:\n",
    "            n = n + 1\n",
    "    return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-06T15:31:50.061792Z"
    }
   },
   "outputs": [],
   "source": [
    "def bin_index(x, min, max):\n",
    "        return int((x-min)/(max-min)*101)\n",
    "\n",
    "def covariance_fit_scipy(predictive_mean, predictive_lower, predictive_upper, best, HIST_INDEX, ax):\n",
    "    def gaus1d(x, A, mean_x, sigma_x):\n",
    "        x = x - mean_x\n",
    "        z = A * np.exp( -0.5 * (x/sigma_x) ** 2 )\n",
    "        return z\n",
    "    def gaus1d_offset(x, A, mean_x, sigma_x, offset):\n",
    "        x = x - mean_x\n",
    "        z = offset + A * np.exp( -0.5 * (x/sigma_x) ** 2 )\n",
    "        return z\n",
    "\n",
    "    def fit_1d(ax):\n",
    "        curr_bin = bins[HIST_INDEX]\n",
    "        title = f\"{curr_bin.m_min} < $M_{{ee}}$ < {curr_bin.m_max}, {curr_bin.z_min} < $cos(\\\\theta^{{CM}}_{{\\gamma*}})$ < {curr_bin.z_max}\"\n",
    "        \n",
    "        mean_x = best[0].item()\n",
    "\n",
    "        scale1 = bounds[1][0].item()\n",
    "        scale2 = bounds[1][0].item()\n",
    "        proj_min_X = bounds[0][0].item()\n",
    "        proj_max_X = bounds[1][0].item()\n",
    "\n",
    "        proj = predictive_mean\n",
    "        proj_lower = predictive_lower\n",
    "        proj_upper = predictive_upper\n",
    "\n",
    "       # xmin_ind = max(0,   bin_index(mean_x, proj_min_X, proj_max_X)-50)\n",
    "       # xmax_ind = min(100, bin_index(mean_x, proj_min_X, proj_max_X)+50)\n",
    "        xmin_ind = 0\n",
    "        xmax_ind = 100\n",
    "        xmin = proj_min_X + xmin_ind / 101. * (proj_max_X - proj_min_X)\n",
    "        xmax = proj_min_X + (xmax_ind + 1) / 101. * (proj_max_X - proj_min_X)\n",
    "\n",
    "        x = np.linspace(-1, 1, 101)\n",
    "\n",
    "        proj1 = proj[xmin_ind:xmax_ind]\n",
    "        print(\"range \", xmin_ind, xmax_ind, xmin, xmax)\n",
    "    \n",
    "       # initial_guess = (1.0, mean_x, 0.2*(proj_max_X-proj_min_X))\n",
    "        initial_guess = (1.0, mean_x, 0.2*(proj_max_X-proj_min_X), 0)\n",
    "        eps = 0.001\n",
    "       # param_bounds = ([0,mean_x-eps,0],[np.inf,mean_x+eps,2])\n",
    "       # if mean_x >= 1.0:\n",
    "       #     param_bounds = ([0,mean_x-eps,0],[np.inf,2,2])\n",
    "        param_bounds = ([0,mean_x-eps,0,-np.inf],[np.inf,mean_x+eps,2,np.inf])\n",
    "        if mean_x >= 1.0:\n",
    "            param_bounds = ([0,mean_x-eps,0,-np.inf],[np.inf,2,2,np.inf])\n",
    "       # ax.plot(x, proj, label=\"Estimated values\")\n",
    "        ax.plot(x, proj)\n",
    "        ax.fill_between(x, proj_lower, proj_upper, alpha=0.5)\n",
    "        ax.plot(x, proj, label=\"Estimated values\")\n",
    "        ax.set_title(title)\n",
    "        ax.set_xlabel(r\"$\\lambda_{\\theta}$\")\n",
    "        ax.set_ylabel(\"ndf$/\\chi^2$\")\n",
    "        ax.set_ylim(0,1.5*proj_upper.max())\n",
    "        try:\n",
    "            popt, pcov = opt.curve_fit(gaus1d_offset, x[xmin_ind:xmax_ind], proj1, p0 = initial_guess, bounds=param_bounds, maxfev=2000)\n",
    "            fit_result = gaus1d_offset(x, *(popt))\n",
    "    \n",
    "            ax.plot(x, fit_result, label=\"Gaussian fit\")\n",
    "           # ax.set_ylim([0,2*predictive_upper.max()])\n",
    "           # plt.rc('axes', titlesize=8)\n",
    "           # plt.rc('axes', labelsize=8) \n",
    "           # plt.rc('xtick', labelsize=8)\n",
    "           # plt.rc('ytick', labelsize=8)\n",
    "            ax.legend()\n",
    "        except RuntimeError as e:\n",
    "            print(f\"There was an exception {e}\")\n",
    "            popt, pcov = None, None\n",
    "        return popt, pcov\n",
    "\n",
    "   # params0, _ = fit_1d(ax[1][0])\n",
    "    params0, _ = fit_1d(ax)\n",
    "    plt.savefig(f\"{DIR_NAME}/chi2_best_{HIST_INDEX}.png\", bbox_inches=\"tight\")\n",
    "\n",
    "    try:\n",
    "        return params0[2]\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-06T15:31:50.062580Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-06T15:31:50.063353Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "with open(f'{DIR_NAME}/results.txt', 'w') as fout:\n",
    "    canvases = []\n",
    "    hdiffs = []\n",
    "    hmodels = []\n",
    "    \n",
    "    fig, ax = plt.subplots(nrows=4, ncols=3)\n",
    "    fig.tight_layout()\n",
    "    fig.set_figheight(20)\n",
    "    fig.set_figwidth(15)\n",
    "   # fig, ax = plt.subplots(nrows=1, ncols=1)\n",
    "    \n",
    "    for HIST_INDEX in range_used:\n",
    "\n",
    "        c_sorted = c_sorted_all[HIST_INDEX - range_used.start]\n",
    "        train_x_sorted = train_x_sorted_all[HIST_INDEX - range_used.start]\n",
    "        predictive_mean = predictive_mean_all[HIST_INDEX - range_used.start]\n",
    "        predictive_lower = predictive_lower_all[HIST_INDEX - range_used.start]\n",
    "        predictive_upper = predictive_upper_all[HIST_INDEX - range_used.start]\n",
    "        predictive_mean_2 = predictive_mean - predictive_mean.min()\n",
    "\n",
    "       # ax = plt.axes()\n",
    "       # fig, ax = plt.subplots(nrows=1, ncols=1)\n",
    "        lambda_theta = train_x_sorted[-1]\n",
    "        bestHistsMC = getHistMakerMC(HIST_INDEX).makeHists(lambda_theta)\n",
    "        hmodels.append(bestHistsMC[0][HIST_INDEX])\n",
    "        \n",
    "        can1 = TCanvas(f\"can_cmp_{HIST_INDEX}\",\"can\",900,600)\n",
    "        can1.Divide(3,2)\n",
    "        can1.Draw()        \n",
    "        canvases.append(can1)\n",
    "        \n",
    "        hdiff1 = plotComparison(can1, 1, 4, bestHistsMC[0][HIST_INDEX], histsData_np[0][HIST_INDEX], HIST_INDEX, \"Best\")\n",
    "        hdiffs.append(hdiff1)\n",
    "        \n",
    "        lambda_theta = train_x_sorted[0]\n",
    "        worstHistsMC = getHistMakerMC(HIST_INDEX).makeHists(lambda_theta)\n",
    "        hmodels.append(worstHistsMC[0][HIST_INDEX])\n",
    "        hdiff2 = plotComparison(can1, 2, 5, worstHistsMC[0][HIST_INDEX], histsData_np[0][HIST_INDEX], HIST_INDEX, \"Worst\")\n",
    "        hdiffs.append(hdiff2)\n",
    "\n",
    "        shift = 0.75\n",
    "        if train_x_sorted[-1] > shift - 1:\n",
    "            diffToBest = torch.tensor([-shift])\n",
    "        else:\n",
    "            diffToBest = torch.tensor([+shift])\n",
    "        lambda_theta = train_x_sorted[-1] + diffToBest\n",
    "        notSoGoodHistsMC = getHistMakerMC(HIST_INDEX).makeHists(lambda_theta)\n",
    "        hmodels.append(notSoGoodHistsMC[0][HIST_INDEX])\n",
    "        hdiff22 = plotComparison(can1, 3, 6, notSoGoodHistsMC[0][HIST_INDEX], histsData_np[0][HIST_INDEX], HIST_INDEX, \"Not so good\")\n",
    "        hdiffs.append(hdiff22)\n",
    "\n",
    "        can1.SaveAs(f\"{DIR_NAME}/comparison_{HIST_INDEX}.gif\")\n",
    "\n",
    "        print(str(HIST_INDEX) + \": Final result:\")\n",
    "        print(str(HIST_INDEX) + \": Final result:\", file=fout)\n",
    "        print(str(HIST_INDEX) + \": lambda_theta = \", c_sorted[-1][1].item())\n",
    "        print(str(HIST_INDEX) + \": lambda_theta = \", c_sorted[-1][1].item(), file=fout)\n",
    "\n",
    "        drphiz = covariance_fit_scipy(predictive_mean,predictive_lower,predictive_upper,train_x_sorted[-1],HIST_INDEX,ax[HIST_INDEX // 3][HIST_INDEX % 3])\n",
    "\n",
    "        n = countCommonNonZeroBins(bestHistsMC[0][HIST_INDEX], histsData_np[0][HIST_INDEX])\n",
    "\n",
    "        try:\n",
    "            print(str(HIST_INDEX) + \": errors = \", drphiz/math.sqrt(1.0*n))\n",
    "            print(str(HIST_INDEX) + \": errors = \", drphiz/math.sqrt(1.0*n), file=fout)\n",
    "        except:\n",
    "            print(str(HIST_INDEX) + \": errors could not be determined\")\n",
    "            print(str(HIST_INDEX) + \": errors could not be determined\", file=fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-06T15:31:50.064092Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-06T15:31:50.064955Z"
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "histsDataCorrs = []\n",
    "hmodelLowM_null = histMakerMC_rho.makeHists((0.0))\n",
    "hmodelLowM_null_mix = histMakerMC_mix.makeHists((0.0))\n",
    "hmodelLowM_null_pi0 = histMakerMC_pi0.makeHists((0.0))\n",
    "pol2s = []\n",
    "paveTexts = []\n",
    "histsAvg = []\n",
    "\n",
    "cc4 = TCanvas(\"cc4\",\"cc4\",900,1200)\n",
    "cc4.Divide(3,4)\n",
    "cc4.Draw()\n",
    "for i, hist in enumerate(histsData_np[0]):\n",
    "    \n",
    "    hist_pp = histsData_pp[0][i]\n",
    "    hist_nn = histsData_nn[0][i]\n",
    "    histAvg = geomAvg1d(hist_pp, hist_nn, 0.2)\n",
    "    histsAvg.append(histAvg)\n",
    "\n",
    "    pad = cc4.cd(i+1)\n",
    "    setPad(pad)\n",
    "    if not isinstance(hist, list):\n",
    "        histCorr = hist.Clone(hist.GetName() + \"_corr\")\n",
    "        histsDataCorrs.append(histCorr)\n",
    "        histCorr.GetXaxis().SetTitle(\"cos(#theta_{e}^{#gamma*})\")\n",
    "        \n",
    "       # histCorr.Add(hist_pp, -1)\n",
    "       # histCorr.Add(hist_nn, -1)\n",
    "       # histCorr.Add(histAvg,-1)\n",
    "        \n",
    "        if event_mixing:\n",
    "            histCorr.Divide(hmodelLowM_null_mix[0][i])\n",
    "            histAvg.Divide(hmodelLowM_null_mix[0][i])\n",
    "           # hist_pp.Divide(hmodelLowM_null_mix[0][i])\n",
    "           # hist_nn.Divide(hmodelLowM_null_mix[0][i])\n",
    "        else:\n",
    "            if i < 3:\n",
    "                histCorr.Divide(hmodelLowM_null_pi0[0][i])\n",
    "                histAvg.Divide(hmodelLowM_null_pi0[0][i])\n",
    "               # hist_pp.Divide(hmodelLowM_null_pi0[0][i])\n",
    "               # hist_nn.Divide(hmodelLowM_null_pi0[0][i])\n",
    "            else:\n",
    "                histCorr.Divide(hmodelLowM_null[0][i])\n",
    "                histAvg.Divide(hmodelLowM_null[0][i])\n",
    "               # hist_pp.Divide(hmodelLowM_null[0][i])\n",
    "               # hist_nn.Divide(hmodelLowM_null[0][i])\n",
    "        hist_pp.Scale(histCorr.Integral()/hist_pp.Integral())\n",
    "        hist_nn.Scale(histCorr.Integral()/hist_nn.Integral())\n",
    "       # print(f\"{i} creating fit function\")\n",
    "        fit = TF1(f\"fit_{i}\", \"[0]*(1+[1]*x*x)\",-1,1)\n",
    "        fit.SetParameters(1, 1)\n",
    "        \n",
    "        if i < 3:\n",
    "            histCorr.Fit(fit,\"Q\",\"\", -0.7, 0.7)\n",
    "        else:\n",
    "            histCorr.Fit(fit,\"Q\")\n",
    "        pol2s.append(fit)\n",
    "            \n",
    "        setTH1(histCorr, histCorr.GetXaxis().GetTitle(), f\"dN/d{histCorr.GetXaxis().GetTitle()} (a.u.)\", \n",
    "               505, 20, 0.8, 1)\n",
    "        histCorr.Draw()\n",
    "       # histCorr.GetYaxis().SetRangeUser(0,2.5)\n",
    "        histCorr.SetMinimum(0)\n",
    "        \n",
    "       # histAvg.Draw(\"SAMEHIST\")\n",
    "        hist_pp.Draw(\"SAMEHIST\")\n",
    "        hist_nn.Draw(\"SAMEHIST\")\n",
    "\n",
    "        caption = f\"#lambda_{{#theta}} = {fit.GetParameter(1):.2f} #pm {fit.GetParError(1):.2f}\"\n",
    "        paveText = setOPT_text(caption, 0.25,0.76,0.675,0.88, 2, 0.04)\n",
    "        paveTexts.append(paveText)\n",
    "        \n",
    "       # print(\"i = \", i)\n",
    "       # for k in range(1, histAvg.GetNbinsX()):\n",
    "       #     print (\"bin: \", k, \", content: \", histAvg.GetBinContent(k))\n",
    "        \n",
    "    else:\n",
    "        print(hist)\n",
    "        \n",
    "\n",
    "cc4.SaveAs(f\"{DIR_NAME}/fit_classic.gif\")\n",
    "cc4.SaveAs(f\"{DIR_NAME}/fit_classic.pdf\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-06T15:31:50.065520Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hmodelLowM_rho = histMakerMC_mix.makeHists((1.0)) if event_mixing else histMakerMC_rho.makeHists((1.0))\n",
    "hmodelLowM_rho[2][0].SetLineColor(8)\n",
    "hmodelLowM_rho[1][0].SetLineColor(8)\n",
    "\n",
    "hmodelLowM = histMakerMC_pi0.makeHists((1.0))\n",
    "\n",
    "fraction = 0.5\n",
    "\n",
    "hmodelLowM[2][0].Scale(1.0/hmodelLowM[2][0].Integral())\n",
    "hmodelLowM[1][0].Scale(1.0/hmodelLowM[1][0].Integral())\n",
    "hmodelLowM_rho[2][0].Scale(1.0/hmodelLowM_rho[2][0].Integral())\n",
    "hmodelLowM_rho[1][0].Scale(1.0/hmodelLowM_rho[1][0].Integral())\n",
    "\n",
    "hmodelLowM[2][0].Add(hmodelLowM_rho[2][0], fraction)\n",
    "hmodelLowM[1][0].Add(hmodelLowM_rho[1][0], fraction)\n",
    "\n",
    "hmodelLowM[2][0].SetLineColor(2)\n",
    "hmodelLowM[1][0].SetLineColor(2)\n",
    "hmodelHigM = getHistMakerMC(3).makeHists(1.0)\n",
    "hmodelHigM[2][1].SetLineColor(2)\n",
    "hmodelHigM[1][1].SetLineColor(2)\n",
    "\n",
    "cc = TCanvas(\"cc\",\"cc\",800,800)\n",
    "cc.Divide(2,2)\n",
    "cc.Draw()\n",
    "\n",
    "pad = cc.cd(1)\n",
    "setPad(pad)\n",
    "dataScale = 1./histsData_np[2][0].Integral()\n",
    "histsData_np[2][0].Scale(dataScale)\n",
    "histsData_pp[2][0].Scale(dataScale)\n",
    "histsData_nn[2][0].Scale(dataScale)\n",
    "hmodelLowM[2][0].Scale(1./hmodelLowM[2][0].Integral())\n",
    "hmodelLowM_rho[2][0].Scale(1./hmodelLowM_rho[2][0].Integral())\n",
    "histsData_np[2][0].GetXaxis().SetTitle(\"cos(#theta^{CM}_{#gamma*})\")\n",
    "histsData_np[2][0].SetTitle(\"Masses below #pi^{0}\")\n",
    "\n",
    "setTH1(histsData_np[2][0], histsData_np[2][0].GetXaxis().GetTitle(), \n",
    "       f\"dN/d{histsData_np[2][0].GetXaxis().GetTitle()} (a.u.)\", 505, 20, 0.8, 1)\n",
    "histsData_np[2][0].Draw()\n",
    "#histsData_pp[2][0].Draw(\"SAME\")\n",
    "#histsData_nn[2][0].Draw(\"SAME\")\n",
    "hmodelLowM[2][0].Draw(\"SAMEHIST\")\n",
    "hmodelLowM_rho[2][0].Draw(\"SAMEHIST\")\n",
    "\n",
    "pad = cc.cd(2)\n",
    "pad.SetLogy()\n",
    "setPad(pad)\n",
    "histsData_np[1][0].Scale(1./histsData_np[1][0].Integral())\n",
    "hmodelLowM[1][0].Scale(1./hmodelLowM[1][0].Integral())\n",
    "hmodelLowM_rho[1][0].Scale(1./hmodelLowM_rho[1][0].Integral())\n",
    "histsData_np[1][0].SetTitle(\"Masses below #pi^{0}\")\n",
    "histsData_np[1][0].GetXaxis().SetTitle(\"#it{M}_{ee} (GeV/#it{c}^{2})\")\n",
    "\n",
    "setTH1(histsData_np[1][0], histsData_np[1][0].GetXaxis().GetTitle(), \n",
    "       f\"dN/d{histsData_np[1][0].GetXaxis().GetTitle()} (a.u.)\", 505, 20, 0.8, 1)\n",
    "histsData_np[1][0].Draw(\"HIST\")\n",
    "hmodelLowM[1][0].Draw(\"SAMEHIST\")\n",
    "hmodelLowM_rho[1][0].Draw(\"SAMEHIST\")\n",
    "\n",
    "legend = TLegend(0.7, 0.7, 0.9, 0.9)\n",
    "legend.AddEntry(histsData_np[1][0], \"exp\", \"pl\")\n",
    "legend.AddEntry(hmodelLowM[1][0], f\"#pi^{{0}} + {fraction}#rho\", \"l\")\n",
    "legend.AddEntry(hmodelLowM_rho[1][0], \"#rho\", \"l\")\n",
    "legend.Draw()\n",
    "\n",
    "pad = cc.cd(3)\n",
    "setPad(pad)\n",
    "histsData_np[2][1].Scale(1./histsData_np[2][1].Integral())\n",
    "hmodelHigM[2][1].Scale(1./hmodelHigM[2][1].Integral())\n",
    "hmodelLowM_rho[2][1].Scale(1./hmodelLowM_rho[2][1].Integral())\n",
    "histsData_np[2][1].GetXaxis().SetTitle(\"cos(#theta^{CM}_{#gamma*})\")\n",
    "histsData_np[2][1].SetTitle(\"Masses above #pi^{0}\")\n",
    "\n",
    "setTH1(histsData_np[2][1], histsData_np[2][1].GetXaxis().GetTitle(), \n",
    "       f\"dN/d{histsData_np[2][1].GetXaxis().GetTitle()} (a.u.)\", 505, 20, 0.8, 1)\n",
    "histsData_np[2][1].Draw()\n",
    "hmodelHigM[2][1].Draw(\"SAMEHIST\")\n",
    "#hmodelLowM_rho[2][1].Draw(\"SAMEHIST\")\n",
    "\n",
    "pad = cc.cd(4)\n",
    "pad.SetLogy()\n",
    "setPad(pad)\n",
    "histsData_np[1][1].Scale(1./histsData_np[1][1].Integral())\n",
    "hmodelHigM[1][1].Scale(1./hmodelHigM[1][1].Integral())\n",
    "hmodelLowM_rho[1][1].Scale(1./hmodelLowM_rho[1][1].Integral())\n",
    "histsData_np[1][1].GetXaxis().SetTitle(\"#it{M}_{ee} (GeV/#it{c}^{2})\")\n",
    "histsData_np[1][1].SetTitle(\"Masses above #pi^{0}\")\n",
    "\n",
    "setTH1(histsData_np[1][1], histsData_np[1][1].GetXaxis().GetTitle(), \n",
    "       f\"dN/d{histsData_np[1][1].GetXaxis().GetTitle()} (a.u.)\", 505, 20, 0.8, 1)\n",
    "histsData_np[1][1].Draw()\n",
    "hmodelHigM[1][1].Draw(\"SAMEHIST\")\n",
    "#hmodelLowM_rho[1][1].Draw(\"SAMEHIST\")\n",
    "\n",
    "cc.SaveAs(f\"{DIR_NAME}/cmp_mass_z.gif\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-06T15:31:50.066225Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "kfactors = []\n",
    "\n",
    "cck = TCanvas(\"cck\",\"cck\",900,1200)\n",
    "cck.Divide(3,4)\n",
    "cck.Draw()\n",
    "for i, hist in enumerate(histsData_np[0]):\n",
    "    \n",
    "    hist_np_mix = histsData_np_mix[0][i]\n",
    "    hist_pp_mix = histsData_pp_mix[0][i]\n",
    "    hist_nn_mix = histsData_nn_mix[0][i]\n",
    "\n",
    "    histAvg = geomAvg1d(hist_pp_mix, hist_nn_mix, 0.2)\n",
    "    hist_np_mix.Divide(histAvg)\n",
    "    kfactors.append(hist_np_mix)\n",
    "\n",
    "    pad = cck.cd(i+1)\n",
    "    setPad(pad)\n",
    "    if not isinstance(hist, list):\n",
    "        hist_np_mix.GetXaxis().SetTitle(\"cos(#theta_{e}^{#gamma*})\")\n",
    "        \n",
    "        setTH1(hist_np_mix, histCorr.GetXaxis().GetTitle(), f\"dN/d{histCorr.GetXaxis().GetTitle()} (a.u.)\", \n",
    "               505, 20, 0.8, 1)\n",
    "        hist_pp_mix.SetLineColor(2)\n",
    "        hist_nn_mix.SetLineColor(4)\n",
    "        hist_pp_mix.SetMarkerColor(2)\n",
    "        hist_nn_mix.SetMarkerColor(4)\n",
    "        hist_np_mix.Draw()\n",
    "        hist_pp_mix.Draw(\"SAME\")\n",
    "        hist_nn_mix.Draw(\"SAME\")\n",
    "        hist_np_mix.SetMinimum(0)\n",
    "        \n",
    "    else:\n",
    "        print(hist)\n",
    "        \n",
    "\n",
    "cck.SaveAs(f\"{DIR_NAME}/kfactor.gif\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-06T15:31:50.066991Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-06T15:31:50.067820Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
