{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %env PYTORCH_ENABLE_MPS_FALLBACK=1\n",
    "%load_ext autoreload\n",
    "%autoreload\n",
    "\n",
    "from bins import Bins\n",
    "from utils import calcOneChi2, HistMaker_1d, diffHist\n",
    "from ROOT import TFile, TH1, TH3F, TF2, TCanvas, TStyle, gStyle, Form, Fit, TLegend\n",
    "import scipy.optimize as opt\n",
    "import math\n",
    "import calendar, os\n",
    "from time import time, gmtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_saved = True\n",
    "range_used = range(0,12)\n",
    "\n",
    "if read_saved:\n",
    "    DIR_NAME = \"results_sameevt_nu15_noise1em1_1d\"\n",
    "else:\n",
    "    current_GMT =   gmtime()\n",
    "    time_stamp = calendar.timegm(current_GMT)\n",
    "    DIR_NAME = f'results_{time_stamp}'\n",
    "    os.mkdir(DIR_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = Bins.readFrom(\"ranges.yml\")\n",
    "#histMakerData_np = HistMaker_1d(\"apr12_diele_088_090_ag123ag_2500A_accepted_np_mix_hc_sample_2.dat\", \"_data\", bins)\n",
    "histMakerData_np = HistMaker_1d(\"apr12_diele_088_090_ag123ag_2500A_accepted_np_2.dat\", \"_data_np\", bins)\n",
    "histsData_np = histMakerData_np.makeHists()\n",
    "histMakerData_pp = HistMaker_1d(\"apr12_diele_088_090_ag123ag_2500A_accepted_pp_2.dat\", \"_data_pp\", bins)\n",
    "histsData_pp = histMakerData_pp.makeHists()\n",
    "histMakerData_nn = HistMaker_1d(\"apr12_diele_088_090_ag123ag_2500A_accepted_nn_2.dat\", \"_data_nn\", bins)\n",
    "histsData_nn = histMakerData_nn.makeHists()\n",
    "histMakerMC_rho = HistMaker_1d(\"mar19_diele_inmedium_heli0cm_np.dat\", \"_MC_rho\", bins)\n",
    "histMakerMC_pi0 = HistMaker_1d(\"mar19_diele_pi0_heli0cm_np.dat\", \"_MC_pi0\", bins)\n",
    "def getHistMakerMC(HIST_INDEX):\n",
    "    return histMakerMC_pi0 if HIST_INDEX < 3 else histMakerMC_rho\n",
    "   # return histMakerMC_rho\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_hists_pi0 = histMakerMC_pi0.builder.base_hists\n",
    "can3 = TCanvas(\"can3\",\"can3\",900,300)\n",
    "can3.Divide(3,1)\n",
    "can3.Draw()\n",
    "for i, hist in enumerate(base_hists_pi0[0]):\n",
    "    if i < 3:\n",
    "        can3.cd(i+1)\n",
    "        if not isinstance(hist, list):\n",
    "            hist.GetXaxis().SetTitle(\"cos(#theta_{e}^{#gamma*})\")\n",
    "            hist.Draw()\n",
    "        else:\n",
    "            print(hist)\n",
    "can3.SaveAs(f\"{DIR_NAME}/base_hists_pi0_MC.gif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_hists_rho = histMakerMC_rho.builder.base_hists\n",
    "can5 = TCanvas(\"can5\",\"can5\",900,1200)\n",
    "can5.Divide(3,4)\n",
    "can5.Draw()\n",
    "for i, hist in enumerate(base_hists_rho[0]):\n",
    "    can5.cd(i+1)\n",
    "    if not isinstance(hist, list):\n",
    "        hist.GetXaxis().SetTitle(\"cos(#theta_{e}^{#gamma*})\")\n",
    "        hist.Draw()\n",
    "    else:\n",
    "        print(hist)\n",
    "can5.SaveAs(f'{DIR_NAME}/base_hists_rho_MC.gif')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "can4 = TCanvas(\"can4\",\"can4\",900,1200)\n",
    "can4.Divide(3,4)\n",
    "can4.Draw()\n",
    "for i, hist in enumerate(histsData_np[0]):\n",
    "    can4.cd(i+1)\n",
    "    if not isinstance(hist, list):\n",
    "        hist.GetXaxis().SetTitle(\"cos(#theta_{e}^{#gamma*})\")\n",
    "        hist.Draw(\"COLZ\")\n",
    "    else:\n",
    "        print(hist)\n",
    "\n",
    "can4.SaveAs(f'{DIR_NAME}/histsData_np.gif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.device(\"mps\")\n",
    "torch.manual_seed(0)\n",
    "\n",
    "import gpytorch\n",
    "import botorch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use(\"bmh\")\n",
    "plt.rcParams[\"figure.figsize\"] = (8, 6)\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TH1.SetDefaultSumw2\n",
    "\n",
    "gpytorch.settings.fast_pred_var()\n",
    "gpytorch.settings.fast_pred_samples()\n",
    "\n",
    "N_PARAMS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.mps.is_available()\n",
    "#mps_device = torch.device(\"mps\")\n",
    "mps_device = torch.device(\"cpu\")\n",
    "bounds = torch.tensor([[-1, ],\n",
    "                       [ 1, ]], dtype=torch.float)\n",
    "bounds = bounds.to(mps_device)\n",
    "\n",
    "\n",
    "xs = torch.linspace(bounds[0][0], bounds[1][0], 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPModel(gpytorch.models.ExactGP, botorch.models.gpytorch.GPyTorchModel):\n",
    "# class GPModel(gpytorch.models.ApproximateGP, botorch.models.gpytorch.GPyTorchModel):\n",
    "    _num_outputs = 1\n",
    "\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super().__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(\n",
    "            gpytorch.kernels.MaternKernel(nu=1.5, ard_num_dims=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        mean_x = mean_x.to(mps_device)\n",
    "        covar_x = covar_x.to(mps_device)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "def fit_gp_model(train_x, train_y, num_train_iters=500):\n",
    "    train_x = train_x.to(mps_device)\n",
    "    train_y = train_y.to(mps_device)\n",
    "\n",
    "    # declare the GP\n",
    "    noise = 1e-1\n",
    "\n",
    "    likelihood = gpytorch.likelihoods.StudentTLikelihood()\n",
    "    likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "    model = GPModel(train_x, train_y, likelihood)\n",
    "    model.likelihood.noise = noise\n",
    "    likelihood = likelihood.to(mps_device)\n",
    "    model = model.to(mps_device)\n",
    "\n",
    "    # train the hyperparameter (the constant)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "    model.train()\n",
    "    likelihood.train()\n",
    "\n",
    "    for i in range(num_train_iters):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(train_x)\n",
    "        loss = -mll(output, train_y)\n",
    "\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    likelihood.eval()\n",
    "\n",
    "    return model.cpu(), likelihood.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Come back to standard version\n",
    "#num_queries = 75\n",
    "num_queries = 200\n",
    "num_repeats = 1\n",
    "num_samples = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -2 is the default value when no feasible has been found\n",
    "default_value = -1\n",
    "\n",
    "def fit_bo(HIST_INDEX = 0):\n",
    "    global bounds\n",
    "\n",
    "    def objective(xx):\n",
    "        def generator(xx):\n",
    "            for x in xx:\n",
    "                lambda_theta = x\n",
    "\n",
    "                histsMC = getHistMakerMC(HIST_INDEX).makeHists(lambda_theta)\n",
    "                chi2, ndf = calcOneChi2(histsMC[0][HIST_INDEX], histsData_np[0][HIST_INDEX])\n",
    "                allHistsMC.append(histsMC[0][HIST_INDEX])\n",
    "                if not chi2 or not ndf:\n",
    "                    return torch.tensor([0])\n",
    "                yield torch.tensor([1.0/(chi2 / ndf)])\n",
    "        return torch.stack([a for a in generator(xx)])\n",
    "\n",
    "    def one_starting_sample():\n",
    "        result = bounds[0] + (bounds[1] - bounds[0]) * torch.rand(N_PARAMS)\n",
    "        return result\n",
    "\n",
    "    feasible_incumbents = torch.ones((num_repeats, num_queries)) * default_value\n",
    "\n",
    "    best_fs = []\n",
    "\n",
    "    print(f\"HIST INDEX: {HIST_INDEX}\")\n",
    "    for trial in range(num_repeats):\n",
    "       # print(\"trial\", trial)\n",
    "\n",
    "        torch.manual_seed(trial)\n",
    "       # train_x = bounds[0] + (bounds[1] - bounds[0]) * torch.rand(num_samples, 3)\n",
    "       # while -2.0*train_x[0][0] - 1.0*train_x[0][2] < -2:\n",
    "       #     train_x = bounds[0] + (bounds[1] - bounds[0]) * torch.rand(num_samples, 3)\n",
    "        train_x = torch.stack([one_starting_sample() for _ in range(num_samples)])\n",
    "        train_utility = objective(train_x).to(mps_device)\n",
    "        train_x = train_x.to(mps_device)\n",
    "\n",
    "        for i in tqdm(range(num_queries)):\n",
    "            feasible_incumbents[trial, i] = train_utility.max()\n",
    "            before_fit_gp = time()\n",
    "            utility_model, utility_likelihood = fit_gp_model(\n",
    "                train_x, train_utility.squeeze(-1)\n",
    "            )\n",
    "            after_fit_gp = time()\n",
    "           # print(\"Fitting GP took \" + str(after_fit_gp - before_fit_gp) + \" seconds\")\n",
    "            best_f = train_utility.max()\n",
    "            best_fs.append(best_f.item())\n",
    "                \n",
    "           # policy = botorch.acquisition.monte_carlo.qExpectedImprovement(\n",
    "           # policy = botorch.acquisition.analytic.LogExpectedImprovement(\n",
    "            policy = botorch.acquisition.logei.qLogExpectedImprovement(\n",
    "          # policy = botorch.acquisition.analytic.LogProbabilityOfImprovement(\n",
    "          # policy = botorch.acquisition.analytic.PosteriorMean(\n",
    "                model=utility_model,\n",
    "                best_f=train_utility.max(),\n",
    "            ).to(mps_device)\n",
    "\n",
    "            before_optimize_acqf = time()\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.filterwarnings('ignore', category=RuntimeWarning)\n",
    "                next_x, acq_val = botorch.optim.optimize_acqf(\n",
    "                    policy,\n",
    "                    bounds=bounds,\n",
    "                    #q=5,\n",
    "                    #num_restarts=5,\n",
    "                    #raw_samples=400,\n",
    "                    q=1,\n",
    "                    num_restarts=40,\n",
    "                    raw_samples=100,\n",
    "                )\n",
    "            after_optimize_acqf = time()\n",
    "           # print(\"Optimizing ACQF took \" + str(after_optimize_acqf - before_optimize_acqf) + \" seconds\")\n",
    "\n",
    "            next_utility = objective(next_x).to(mps_device)\n",
    "\n",
    "            train_x = torch.cat([train_x, next_x])\n",
    "            train_utility = torch.cat([train_utility, next_utility])\n",
    "    torch.save(feasible_incumbents, f\"{DIR_NAME}/incumbents_\" + str(HIST_INDEX) + \".pth\")\n",
    "    fout = TFile(f\"{DIR_NAME}/out_{HIST_INDEX}.root\",\"RECREATE\")\n",
    "    fout.cd()\n",
    "    for hist in allHistsMC:\n",
    "       # print (\"Writing hist: \", hist.GetName())\n",
    "        hist.Write()\n",
    "    for j, hists in enumerate(histsData_np):\n",
    "        for k, hist in enumerate(hists):\n",
    "                hist.Write()\n",
    "               # print (\"Writing hist: \", j, k, hist)\n",
    "    fout.Close()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        predictive_distribution = utility_likelihood(utility_model(xs))\n",
    "        acquisition_score = policy(xs.unsqueeze(1))\n",
    "\n",
    "    lambda_thetas     = train_x.flatten()\n",
    "    \n",
    "    c = torch.stack((\n",
    "        torch.arange(0,num_queries, dtype=int),\n",
    "        lambda_thetas[0:num_queries],\n",
    "        train_utility.squeeze()[0:num_queries],\n",
    "        (feasible_incumbents==feasible_incumbents.max())[0],\n",
    "        feasible_incumbents[0]\n",
    "    ),0).transpose(-2,-1)\n",
    "    torch.set_printoptions(precision=4,threshold=10_000, linewidth=120)\n",
    "    sort_index = c[:, N_PARAMS + 1].sort()[1]\n",
    "    c_sorted = c[sort_index]\n",
    "    train_x_sorted = train_x[sort_index]\n",
    "\n",
    "    return c_sorted, train_x_sorted, predictive_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_sorted_all = []\n",
    "train_x_sorted_all = []\n",
    "predictive_mean_all = []\n",
    "predictive_lower_all = []\n",
    "predictive_upper_all = []\n",
    "\n",
    "for HIST_INDEX in range_used:\n",
    "    allHistsMC = []\n",
    "    if read_saved:\n",
    "        c_sorted = torch.load(f\"{DIR_NAME}/c_sorted_\" + str(HIST_INDEX) + \".pth\")\n",
    "        train_x_sorted = torch.load(f\"{DIR_NAME}/train_x_sorted_\" + str(HIST_INDEX) + \".pth\")\n",
    "        predictive_distribution = torch.load(f\"{DIR_NAME}/predictive_distribution_\" + str(HIST_INDEX) + \".pth\")\n",
    "\n",
    "        file = TFile(f\"{DIR_NAME}/out_{HIST_INDEX}.root\", \"read\")\n",
    "        names = [key.GetName() for key in file.GetListOfKeys()]\n",
    "        names = [name for name in names if \"MC\" in name]\n",
    "        for name in names:\n",
    "            allHistsMC.append(file.Get(name))\n",
    "    else:\n",
    "        c_sorted, train_x_sorted, predictive_distribution = fit_bo(HIST_INDEX)\n",
    "        print(c_sorted[-5:])\n",
    "        \n",
    "        torch.save(c_sorted, f\"{DIR_NAME}/c_sorted_\" + str(HIST_INDEX) + \".pth\")\n",
    "        torch.save(train_x_sorted, f\"{DIR_NAME}/train_x_sorted_\" + str(HIST_INDEX) + \".pth\")\n",
    "        torch.save(predictive_distribution, f\"{DIR_NAME}/predictive_distribution_\" + str(HIST_INDEX) + \".pth\")\n",
    "\n",
    "    predictive_mean = predictive_distribution.mean\n",
    "    predictive_lower, predictive_upper = predictive_distribution.confidence_region()\n",
    "    print(\"AFTER_READING: \", predictive_mean[100], predictive_lower[100], predictive_upper[100])\n",
    "\n",
    "    c_sorted_all.append(c_sorted)\n",
    "    train_x_sorted_all.append(train_x_sorted)\n",
    "    predictive_mean_all.append(predictive_mean)\n",
    "    predictive_lower_all.append(predictive_lower)\n",
    "    predictive_upper_all.append(predictive_upper)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact, Layout, IntSlider, FloatSlider\n",
    "import numpy as np\n",
    "\n",
    "axis_title = r\"$cos(\\theta_e^{\\gamma*})$\"\n",
    "\n",
    "def oneplot(ax, tensor, title):\n",
    "        \n",
    "        global xs\n",
    "        \n",
    "       # pos = ax.plot(xs, tensor, ymin=0, ymax=tensor.max())\n",
    "        pos = ax.plot(xs, tensor)\n",
    "       # ax.set_aspect((extent[1]-extent[0])/(extent[3]-extent[2]))\n",
    "        ax.set_title(title)\n",
    "        ax.set_xlabel(axis_title)\n",
    "\n",
    "# def f(ax):\n",
    "#        return oneplot(ax, predictive_mean, r\"ndf$/\\chi^2$\")\n",
    "\n",
    "gStyle.SetOptStat(0)\n",
    "\n",
    "can_cmp_ind = 0\n",
    "\n",
    "def plotComparison(can, pad_nr1, pad_nr2, histMC, histData, hist_index, pull_title):\n",
    "   # print(f\"PLOTTING: {histMC.GetName()} and {histData.GetName()}\")\n",
    "    global can_cmp_ind\n",
    "\n",
    "    curr_bin = bins[hist_index]\n",
    "    title = f\"{curr_bin.m_min} < #it{{M}}_{{ee}} < {curr_bin.m_max}, {curr_bin.z_min} < cos(#theta^{{CM}}_{{#gamma*}}) < {curr_bin.z_max}\"\n",
    "    \n",
    "    pad = can.cd(pad_nr1)\n",
    "    pad.SetRightMargin(0.16)\n",
    "    histData.GetXaxis().SetTitle(\"cos(#theta_{e}^{#gamma*})\")\n",
    "    histData.SetTitle(title)\n",
    "    histData.Draw()\n",
    "    histMC.SetLineColor(2)\n",
    "    histMC.Draw(\"SAMEHIST\")\n",
    "    pad = can.cd(pad_nr2)\n",
    "    pad.SetRightMargin(0.16)\n",
    "    hdiff = diffHist(histMC, histData)\n",
    "    hdiff.SetTitle(pull_title)\n",
    "    hdiff.GetYaxis().SetTitle(\"Pull value\")\n",
    "    hdiff.Draw(\"HIST\")\n",
    "    can.Update()\n",
    "    can.Modified()\n",
    "    can.Update()\n",
    "    \n",
    "    return hdiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_index(x, min, max):\n",
    "        return int((x-min)/(max-min)*101)\n",
    "\n",
    "def covariance_fit_scipy(predictive_mean, predictive_lower, predictive_upper, best, HIST_INDEX, ax):\n",
    "    def gaus1d(x, A, mean_x, sigma_x):\n",
    "        x = x - mean_x\n",
    "        z = A * np.exp( -0.5 * (x/sigma_x) ** 2 )\n",
    "        return z\n",
    "    def gaus1d_offset(x, A, mean_x, sigma_x, offset):\n",
    "        x = x - mean_x\n",
    "        z = offset + A * np.exp( -0.5 * (x/sigma_x) ** 2 )\n",
    "        return z\n",
    "\n",
    "    def fit_1d(ax):\n",
    "        curr_bin = bins[HIST_INDEX]\n",
    "        title = f\"{curr_bin.m_min} < $M_{{ee}}$ < {curr_bin.m_max}, {curr_bin.z_min} < $cos(\\\\theta^{{CM}}_{{\\gamma*}})$ < {curr_bin.z_max}\"\n",
    "        \n",
    "        mean_x = best[0].item()\n",
    "\n",
    "        scale1 = bounds[1][0].item()\n",
    "        scale2 = bounds[1][0].item()\n",
    "        proj_min_X = bounds[0][0].item()\n",
    "        proj_max_X = bounds[1][0].item()\n",
    "\n",
    "        proj = predictive_mean\n",
    "        proj_lower = predictive_lower\n",
    "        proj_upper = predictive_upper\n",
    "\n",
    "       # xmin_ind = max(0,   bin_index(mean_x, proj_min_X, proj_max_X)-50)\n",
    "       # xmax_ind = min(100, bin_index(mean_x, proj_min_X, proj_max_X)+50)\n",
    "        xmin_ind = 0\n",
    "        xmax_ind = 100\n",
    "        xmin = proj_min_X + xmin_ind / 101. * (proj_max_X - proj_min_X)\n",
    "        xmax = proj_min_X + (xmax_ind + 1) / 101. * (proj_max_X - proj_min_X)\n",
    "\n",
    "        x = np.linspace(-1, 1, 101)\n",
    "\n",
    "        proj1 = proj[xmin_ind:xmax_ind]\n",
    "        print(\"range \", xmin_ind, xmax_ind, xmin, xmax)\n",
    "    \n",
    "       # initial_guess = (1.0, mean_x, 0.2*(proj_max_X-proj_min_X))\n",
    "        initial_guess = (1.0, mean_x, 0.2*(proj_max_X-proj_min_X), 0)\n",
    "        eps = 0.001\n",
    "       # param_bounds = ([0,mean_x-eps,0],[np.inf,mean_x+eps,2])\n",
    "       # if mean_x >= 1.0:\n",
    "       #     param_bounds = ([0,mean_x-eps,0],[np.inf,2,2])\n",
    "        param_bounds = ([0,mean_x-eps,0,-np.inf],[np.inf,mean_x+eps,2,np.inf])\n",
    "        if mean_x >= 1.0:\n",
    "            param_bounds = ([0,mean_x-eps,0,-np.inf],[np.inf,2,2,np.inf])\n",
    "        ax.plot(x, proj, label=\"Estimated values\")\n",
    "        ax.fill_between(x, proj_lower, proj_upper, alpha=0.5)\n",
    "        ax.plot(x, proj, label=\"Estimated values\")\n",
    "        ax.set_title(title)\n",
    "        ax.set_xlabel(r\"$\\lambda_{\\theta}$\")\n",
    "        ax.set_ylabel(\"ndf$/\\chi^2$\")\n",
    "        try:\n",
    "            popt, pcov = opt.curve_fit(gaus1d_offset, x[xmin_ind:xmax_ind], proj1, p0 = initial_guess, bounds=param_bounds, maxfev=2000)\n",
    "            fit_result = gaus1d_offset(x, *(popt))\n",
    "    \n",
    "            ax.plot(x, fit_result, label=\"Gaussian fit\")\n",
    "            ax.set_ylim([0,1.5*predictive_upper.max()])\n",
    "            ax.legend()\n",
    "        except RuntimeError as e:\n",
    "            print(f\"There was an exception {e}\")\n",
    "            popt, pcov = None, None\n",
    "        return popt, pcov\n",
    "\n",
    "   # params0, _ = fit_1d(ax[1][0])\n",
    "    params0, _ = fit_1d(ax)\n",
    "    plt.savefig(f\"{DIR_NAME}/chi2_best_{HIST_INDEX}.png\", bbox_inches=\"tight\")\n",
    "\n",
    "    try:\n",
    "        return params0[2]\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(f'{DIR_NAME}/results.txt', 'w') as fout:\n",
    "    canvases = []\n",
    "    hdiffs = []\n",
    "    hmodels = []\n",
    "    \n",
    "    for HIST_INDEX in range_used:\n",
    "\n",
    "        c_sorted = c_sorted_all[HIST_INDEX - range_used.start]\n",
    "        train_x_sorted = train_x_sorted_all[HIST_INDEX - range_used.start]\n",
    "        predictive_mean = predictive_mean_all[HIST_INDEX - range_used.start]\n",
    "        predictive_lower = predictive_lower_all[HIST_INDEX - range_used.start]\n",
    "        predictive_upper = predictive_upper_all[HIST_INDEX - range_used.start]\n",
    "        predictive_mean_2 = predictive_mean - predictive_mean.min()\n",
    "\n",
    "       # ax = plt.axes()\n",
    "        fig, ax = plt.subplots(nrows=1, ncols=1)\n",
    "        lambda_theta = train_x_sorted[-1]\n",
    "        bestHistsMC = getHistMakerMC(HIST_INDEX).makeHists(lambda_theta)\n",
    "        hmodels.append(bestHistsMC[0][HIST_INDEX])\n",
    "        \n",
    "        can1 = TCanvas(f\"can_cmp_{HIST_INDEX}\",\"can\",600,900)\n",
    "        can1.Divide(2,3)\n",
    "        can1.Draw()        \n",
    "        canvases.append(can1)\n",
    "        \n",
    "        hdiff1 = plotComparison(can1, 1, 2, bestHistsMC[0][HIST_INDEX], histsData_np[0][HIST_INDEX], HIST_INDEX, \"Best\")\n",
    "        hdiffs.append(hdiff1)\n",
    "        \n",
    "        lambda_theta = train_x_sorted[0]\n",
    "        worstHistsMC = getHistMakerMC(HIST_INDEX).makeHists(lambda_theta)\n",
    "        hmodels.append(worstHistsMC[0][HIST_INDEX])\n",
    "        hdiff2 = plotComparison(can1, 3, 4, worstHistsMC[0][HIST_INDEX], histsData_np[0][HIST_INDEX], HIST_INDEX, \"Worst\")\n",
    "        hdiffs.append(hdiff2)\n",
    "\n",
    "        shift = 0.75\n",
    "        if train_x_sorted[-1] > shift - 1:\n",
    "            diffToBest = torch.tensor([-shift])\n",
    "        else:\n",
    "            diffToBest = torch.tensor([+shift])\n",
    "        lambda_theta = train_x_sorted[-1] + diffToBest\n",
    "        notSoGoodHistsMC = getHistMakerMC(HIST_INDEX).makeHists(lambda_theta)\n",
    "        hmodels.append(notSoGoodHistsMC[0][HIST_INDEX])\n",
    "        hdiff22 = plotComparison(can1, 5, 6, notSoGoodHistsMC[0][HIST_INDEX], histsData_np[0][HIST_INDEX], HIST_INDEX, \"Not so good\")\n",
    "        hdiffs.append(hdiff22)\n",
    "\n",
    "        can1.SaveAs(f\"{DIR_NAME}/comparison_{HIST_INDEX}.gif\")\n",
    "\n",
    "        print(str(HIST_INDEX) + \": Final result:\")\n",
    "        print(str(HIST_INDEX) + \": Final result:\", file=fout)\n",
    "        print(str(HIST_INDEX) + \": lambda_theta = \", c_sorted[-1][1].item())\n",
    "        print(str(HIST_INDEX) + \": lambda_theta = \", c_sorted[-1][1].item(), file=fout)\n",
    "\n",
    "        drphiz = covariance_fit_scipy(predictive_mean,predictive_lower,predictive_upper,train_x_sorted[-1],HIST_INDEX,ax)\n",
    "\n",
    "        try:\n",
    "            print(str(HIST_INDEX) + \": errors = \", drphiz)\n",
    "            print(str(HIST_INDEX) + \": errors = \", drphiz, file=fout)\n",
    "        except:\n",
    "            print(str(HIST_INDEX) + \": errors could not be determined\")\n",
    "            print(str(HIST_INDEX) + \": errors could not be determined\", file=fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hmodelLowM_rho = histMakerMC_rho.makeHists((1.0))\n",
    "hmodelLowM_rho[2][0].SetLineColor(8)\n",
    "hmodelLowM_rho[1][0].SetLineColor(8)\n",
    "\n",
    "hmodelLowM = histMakerMC_pi0.makeHists((1.0))\n",
    "\n",
    "fraction = 0.25\n",
    "\n",
    "hmodelLowM[2][0].Scale(1.0/hmodelLowM[2][0].Integral())\n",
    "hmodelLowM[1][0].Scale(1.0/hmodelLowM[1][0].Integral())\n",
    "hmodelLowM_rho[2][0].Scale(1.0/hmodelLowM_rho[2][0].Integral())\n",
    "hmodelLowM_rho[1][0].Scale(1.0/hmodelLowM_rho[1][0].Integral())\n",
    "\n",
    "hmodelLowM[2][0].Add(hmodelLowM_rho[2][0], fraction)\n",
    "hmodelLowM[1][0].Add(hmodelLowM_rho[1][0], fraction)\n",
    "\n",
    "hmodelLowM[2][0].SetLineColor(2)\n",
    "hmodelLowM[1][0].SetLineColor(2)\n",
    "hmodelHigM = getHistMakerMC(3).makeHists(1.0)\n",
    "hmodelHigM[2][1].SetLineColor(2)\n",
    "hmodelHigM[1][1].SetLineColor(2)\n",
    "\n",
    "cc = TCanvas(\"cc\",\"cc\",800,800)\n",
    "cc.Divide(2,2)\n",
    "cc.Draw()\n",
    "\n",
    "cc.cd(1)\n",
    "dataScale = 1./histsData_np[2][0].Integral()\n",
    "histsData_np[2][0].Scale(dataScale)\n",
    "histsData_pp[2][0].Scale(dataScale)\n",
    "histsData_nn[2][0].Scale(dataScale)\n",
    "hmodelLowM[2][0].Scale(1./hmodelLowM[2][0].Integral())\n",
    "hmodelLowM_rho[2][0].Scale(1./hmodelLowM_rho[2][0].Integral())\n",
    "histsData_np[2][0].GetXaxis().SetTitle(\"cos(#theta^{CM}_{#gamma*})\")\n",
    "histsData_np[2][0].SetTitle(\"Masses below #pi^{0}\")\n",
    "histsData_np[2][0].Draw()\n",
    "#histsData_pp[2][0].Draw(\"SAME\")\n",
    "#histsData_nn[2][0].Draw(\"SAME\")\n",
    "hmodelLowM[2][0].Draw(\"SAMEHIST\")\n",
    "hmodelLowM_rho[2][0].Draw(\"SAMEHIST\")\n",
    "\n",
    "pad = cc.cd(2)\n",
    "pad.SetLogy()\n",
    "histsData_np[1][0].Scale(1./histsData_np[1][0].Integral())\n",
    "hmodelLowM[1][0].Scale(1./hmodelLowM[1][0].Integral())\n",
    "hmodelLowM_rho[1][0].Scale(1./hmodelLowM_rho[1][0].Integral())\n",
    "histsData_np[1][0].SetTitle(\"Masses below #pi^{0}\")\n",
    "histsData_np[1][0].GetXaxis().SetTitle(\"#it{M}_{ee} (GeV/#it{c}^{2})\")\n",
    "histsData_np[1][0].Draw(\"HIST\")\n",
    "hmodelLowM[1][0].Draw(\"SAMEHIST\")\n",
    "hmodelLowM_rho[1][0].Draw(\"SAMEHIST\")\n",
    "\n",
    "legend = TLegend(0.7, 0.7, 0.9, 0.9)\n",
    "legend.AddEntry(histsData_np[1][0], \"exp\", \"pl\")\n",
    "legend.AddEntry(hmodelLowM[1][0], \"#pi^{0}\", \"l\")\n",
    "legend.AddEntry(hmodelLowM_rho[1][0], \"#rho\", \"l\")\n",
    "legend.Draw()\n",
    "\n",
    "cc.cd(3)\n",
    "histsData_np[2][1].Scale(1./histsData_np[2][1].Integral())\n",
    "hmodelHigM[2][1].Scale(1./hmodelHigM[2][1].Integral())\n",
    "hmodelLowM_rho[2][1].Scale(1./hmodelLowM_rho[2][1].Integral())\n",
    "histsData_np[2][1].GetXaxis().SetTitle(\"cos(#theta^{CM}_{#gamma*})\")\n",
    "histsData_np[2][1].SetTitle(\"Masses above #pi^{0}\")\n",
    "histsData_np[2][1].Draw()\n",
    "hmodelHigM[2][1].Draw(\"SAMEHIST\")\n",
    "hmodelLowM_rho[2][1].Draw(\"SAMEHIST\")\n",
    "\n",
    "pad = cc.cd(4)\n",
    "pad.SetLogy()\n",
    "histsData_np[1][1].Scale(1./histsData_np[1][1].Integral())\n",
    "hmodelHigM[1][1].Scale(1./hmodelHigM[1][1].Integral())\n",
    "hmodelLowM_rho[1][1].Scale(1./hmodelLowM_rho[1][1].Integral())\n",
    "histsData_np[1][1].GetXaxis().SetTitle(\"#it{M}_{ee} (GeV/#it{c}^{2})\")\n",
    "histsData_np[1][1].SetTitle(\"Masses above #pi^{0}\")\n",
    "histsData_np[1][1].Draw()\n",
    "hmodelHigM[1][1].Draw(\"SAMEHIST\")\n",
    "hmodelLowM_rho[1][1].Draw(\"SAMEHIST\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "histsDataCorrs = []\n",
    "hmodelLowM_null = histMakerMC_rho.makeHists((0.0))\n",
    "\n",
    "cc4 = TCanvas(\"cc4\",\"cc4\",900,1200)\n",
    "cc4.Divide(3,4)\n",
    "cc4.Draw()\n",
    "for i, hist in enumerate(histsData_np[0]):\n",
    "\n",
    "    cc4.cd(i+1)\n",
    "    if not isinstance(hist, list):\n",
    "        histCorr = hist.Clone(hist.GetName() + \"_corr\")\n",
    "        histsDataCorrs.append(histCorr)\n",
    "        histCorr.GetXaxis().SetTitle(\"cos(#theta_{e}^{#gamma*})\")\n",
    "        \n",
    "        histCorr.Divide(hmodelLowM_null[0][i])\n",
    "        histCorr.Draw()\n",
    "        histCorr.GetYaxis().SetRangeUser(0,2.5)\n",
    "        histCorr.SetMinimum(0)\n",
    "        \n",
    "    else:\n",
    "        print(hist)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
